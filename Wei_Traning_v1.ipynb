{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import OneHotEncoder, scale, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import ensemble\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_target(df):\n",
    "    # drop those records that have missing actual delivery time\n",
    "    df = df[pd.notnull(df['actual_delivery_time'])]\n",
    "    #df['created_at_datetime'] = df['created_at'].astype(\"datetime64[s]\")\n",
    "    #df['actual_delivery_time_datetime'] = df['actual_delivery_time'].astype(\"datetime64[s]\")\n",
    "    df['duration'] = df['actual_delivery_time'].astype(\"datetime64[s]\") - df['created_at'].astype(\"datetime64[s]\")\n",
    "    df['duration'] = df['duration'] / np.timedelta64(1, 's')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_time_feature(df):\n",
    "    \n",
    "    #create created_at_year, created_at_month, created_at_day, created_at_date, created_at_dayOfWeek, \n",
    "    #created_at_time, created_at_hour, created_at_minute, created_at_second, created_at_isWeekend,\n",
    "    #created_at_isHoliday\n",
    "    \n",
    "    df['created_at_datetime'] = df['created_at'].astype(\"datetime64[s]\")\n",
    "    #df['actual_delivery_time_datetime'] = df['actual_delivery_time'].astype(\"datetime64[s]\")\n",
    "\n",
    "    df['created_at_year'], df['created_at_month'], df['created_at_day'], df['created_at_date'], df['created_at_dayOfWeek'], df['created_at_time'], df['created_at_hour'], df['created_at_minute'], df['created_at_second'] = df['created_at_datetime'].dt.year, df['created_at_datetime'].dt.month, df['created_at_datetime'].dt.day, df['created_at_datetime'].dt.date, df['created_at_datetime'].dt.dayofweek, df['created_at_datetime'].dt.time, df['created_at_datetime'].dt.hour, df['created_at_datetime'].dt.minute, df['created_at_datetime'].dt.second\n",
    "\n",
    "    df.loc[df['created_at_dayOfWeek'].isin([5, 6]), 'created_at_isWeekend'] = 1\n",
    "    df.loc[df['created_at_dayOfWeek'].isin([0, 1, 2, 3, 4]), 'created_at_isWeekend'] = 0\n",
    "\n",
    "    cal = calendar()\n",
    "    holidays = cal.holidays(start=df['created_at_date'].min(), end=df['created_at_date'].max())\n",
    "    df['created_at_isHoliday'] = np.where(df.created_at_datetime.dt.normalize().isin(holidays), 1, 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_continuous_features(df):\n",
    "    \n",
    "    def bin_num(x, a=251, b=446):\n",
    "        if x == a:\n",
    "             return 'fast'\n",
    "        elif x == b:\n",
    "             return 'slow'\n",
    "        else:\n",
    "            return 'other'\n",
    "    \n",
    "    #df = df.loc[(df['total_items'] < 20)]\n",
    "    #df = df.loc[df['subtotal'] < 12000]\n",
    "    #df = df.loc[df['num_distinct_items'] < 16]\n",
    "    #df = df.loc[(df['min_item_price'] > 0) & (df['min_item_price'] <= 5000)]\n",
    "    #df = df.loc[(df['max_item_price'] > 0) & (df['max_item_price'] <= 5000)]\n",
    "    \n",
    "    df['total_items'][(df['total_items'] > 20)] = 20\n",
    "    df['subtotal'][df['subtotal'] > 12000] = 12000\n",
    "    df['num_distinct_items'][df['num_distinct_items'] > 16] = 16\n",
    "    df['min_item_price'][(df['min_item_price'] < 0)] = 0\n",
    "    df['min_item_price'][(df['min_item_price'] > 5000)] = 5000\n",
    "\n",
    "    df['max_item_price'][(df['max_item_price'] < 0)] = 0\n",
    "    df['max_item_price'][(df['max_item_price'] > 5000)] = 5000\n",
    "\n",
    "    \n",
    "    #df = df.loc[df['total_onshift_dashers'] > 0]\n",
    "    df['total_onshift_dashers'][df['total_onshift_dashers'] < 0] = 0\n",
    "    df['total_onshift_dashers'] = df['total_onshift_dashers'].fillna(int(df['total_onshift_dashers'].mean()))\n",
    "    \n",
    "    #df = df.loc[df['total_busy_dashers'] > 0]\n",
    "    df['total_busy_dashers'][df['total_busy_dashers'] < 0] = 0\n",
    "    df['total_busy_dashers'] = df['total_busy_dashers'].fillna(int(df['total_busy_dashers'].mean()))\n",
    "    \n",
    "    #df = df.loc[df['total_outstanding_orders'] > 0]\n",
    "    df['total_outstanding_orders'][df['total_outstanding_orders'] < 0] = 0\n",
    "    df['total_outstanding_orders'] = df['total_outstanding_orders'].fillna(int(df['total_outstanding_orders'].mean()))\n",
    "    \n",
    "    df['estimated_order_place_duration_rebinned'] =  df['estimated_order_place_duration'].apply(bin_num)\n",
    "    df['estimated_store_to_consumer_driving_duration'] = df['estimated_store_to_consumer_driving_duration'].fillna(int(df['estimated_store_to_consumer_driving_duration'].mean()))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate number of orders for each store\n",
    "def make_store_id_cont(df):\n",
    "    store_counts_df = pd.DataFrame(df['store_id'].value_counts().reset_index().rename(columns={'index': 'store_id', 0: 'store_id_count'}))\n",
    "    store_counts_df.columns = ['store_id', 'store_id_count']\n",
    "    store_counts_df = store_counts_df.sort_values(by='store_id', ascending=True)\n",
    "    df = pd.merge(df, store_counts_df, on='store_id', how='left')\n",
    "    df['store_id_rebinned'] = df['store_id']\n",
    "    df['store_id_rebinned'][(df['store_id_count'] <500) & (df['store_id_count'] >= 400)] = '[400, 500)'\n",
    "    df['store_id_rebinned'][(df['store_id_count'] <400) & (df['store_id_count'] >= 200)] = '[200, 400)'\n",
    "    df['store_id_rebinned'][(df['store_id_count'] <200) & (df['store_id_count'] >= 50)] = '[50, 200)'\n",
    "    df['store_id_rebinned'][df['store_id_count'] <50] = '[0, 50)'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_store_category(df):\n",
    "    df['store_primary_category'][df['store_primary_category'].isnull()] = 'Unknown'\n",
    "    \n",
    "    store_primary_category_counts_df = pd.DataFrame(df['store_primary_category'].value_counts().reset_index().rename(columns={'index': 'store_primary_category', 0: 'store_primary_category_count'}))\n",
    "    store_primary_category_counts_df.columns = ['store_primary_category', 'store_primary_category_count']\n",
    "    df = pd.merge(df, store_primary_category_counts_df, on='store_primary_category', how='left')\n",
    "    \n",
    "    #lst_store_primary_category=df['store_primary_category'].tolist()\n",
    "    #lst_store_primary_category_cnt = df['store_primary_category_count'].tolist()\n",
    "    #lst_store_primary_category_bin = [lst_store_primary_category[i] if lst_store_primary_category_cnt[i] > 300 else \"other2\" for i in range(len(lst_store_primary_category)) ]   \n",
    "    #df['store_primary_category_rebinned'] = lst_store_primary_category_bin\n",
    "    \n",
    "    df['store_primary_category_rebinned'] = df['store_primary_category']\n",
    "    df['store_primary_category_rebinned'][df['store_primary_category_rebinned'].isnull()] = 'Unknown'\n",
    "    df['store_primary_category_rebinned'][(df['store_primary_category_count'] <3000) & (df['store_primary_category_count'] >= 2000)] = '[2000, 3000)'\n",
    "    df['store_primary_category_rebinned'][(df['store_primary_category_count'] <2000) & (df['store_primary_category_count'] >= 1000)] = '[1000, 2000)'\n",
    "    df['store_primary_category_rebinned'][(df['store_primary_category_count'] <1000) & (df['store_primary_category_count'] >= 200)] = '[200, 1000)'\n",
    "    df['store_primary_category_rebinned'][df['store_primary_category_count'] <200] = '[0, 200)'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute_market_id(df):\n",
    "    df['market_id'][df['market_id'].isnull()] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_order_protocol(df):\n",
    "    df['order_protocol'][df['order_protocol'].isnull()] = 0\n",
    "    df['order_protocol'].loc[df['order_protocol'] == 6] = 0\n",
    "    df['order_protocol'].loc[df['order_protocol'] == 7] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(df,TrainOrScore):\n",
    "    if TrainOrScore == 'Train':\n",
    "        TrainFeatures = df[['duration', 'market_id', 'store_id_rebinned', 'store_primary_category_rebinned',\n",
    "                            'order_protocol',  'total_items', 'subtotal', 'num_distinct_items', 'min_item_price',\n",
    "                            'max_item_price','total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders',\n",
    "                            'estimated_store_to_consumer_driving_duration', 'created_at_month', 'created_at_dayOfWeek',\n",
    "                            'created_at_hour', 'created_at_isWeekend', 'created_at_isHoliday',\n",
    "                            'estimated_order_place_duration_rebinned']]\n",
    "    else:\n",
    "        TrainFeatures = df[['market_id', 'store_id_rebinned', 'store_primary_category_rebinned',\n",
    "                    'order_protocol',  'total_items', 'subtotal', 'num_distinct_items', 'min_item_price',\n",
    "                    'max_item_price','total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders',\n",
    "                    'estimated_store_to_consumer_driving_duration', 'created_at_month', 'created_at_dayOfWeek',\n",
    "                    'created_at_hour', 'created_at_isWeekend', 'created_at_isHoliday',\n",
    "                    'estimated_order_place_duration_rebinned']]\n",
    "        \n",
    "    TrainFeatures[['market_id', 'store_id_rebinned', 'store_primary_category_rebinned', 'order_protocol', 'created_at_month',\n",
    "                   'created_at_dayOfWeek', 'created_at_hour',  'created_at_isWeekend', 'created_at_isHoliday', \n",
    "                   'estimated_order_place_duration_rebinned']] = TrainFeatures[['market_id', 'store_id_rebinned', \n",
    "                                                                               'store_primary_category_rebinned', \n",
    "                                                                                'order_protocol',\n",
    "                                                                                'created_at_month', 'created_at_dayOfWeek',\n",
    "                                                                                'created_at_hour',  'created_at_isWeekend',\n",
    "                                                                                'created_at_isHoliday', 'estimated_order_place_duration_rebinned']].astype(object)\n",
    "    NumFeatures = ['total_items', 'subtotal', 'num_distinct_items', 'min_item_price',  'max_item_price',\n",
    "                   'total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders',\n",
    "                   'estimated_store_to_consumer_driving_duration']\n",
    "    CatFeatures = ['market_id', 'store_id_rebinned', 'store_primary_category_rebinned',  'order_protocol',\n",
    "                   'created_at_month', 'created_at_dayOfWeek', 'created_at_hour', 'created_at_isWeekend',\n",
    "                   'created_at_isHoliday', 'estimated_order_place_duration_rebinned']\n",
    "    return TrainFeatures, NumFeatures, CatFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_oneHot_X(input_x, features_num, features_cat):\n",
    "    # scale numerical features\n",
    "    input_x_scale = scale(input_x[features_num])\n",
    "    \n",
    "    # OneHot cat features\n",
    "    le=LabelEncoder()\n",
    "    enc = OneHotEncoder()\n",
    "    \n",
    "    Cat_Train = input_x[features_cat].apply(le.fit_transform)\n",
    "    enc.fit(Cat_Train)\n",
    "    input_x_oneHot = enc.transform(Cat_Train).toarray()\n",
    "    \n",
    "    output_x = pd.concat([pd.DataFrame(input_x_scale), pd.DataFrame(input_x_oneHot)], axis=1)\n",
    "\n",
    "    return output_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_model(X_train, Y_train, X_test, Y_test):\n",
    "    lm = linear_model.LinearRegression()\n",
    "    lm.fit(X_train, Y_train)\n",
    "    lm_predict_train = lm.predict(X_train)\n",
    "    lm_predict_test = lm.predict(X_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, lm_predict_train)))\n",
    "    #Root mean squared error for train 896.74\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, lm_predict_test)))\n",
    "    #Root mean squared error for test: 893.58\n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_model(X_train, Y_train, X_test, Y_test):\n",
    "    rf = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    rf_predict_train = rf.predict(X_train)\n",
    "    rf_predict_test = rf.predict(X_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, rf_predict_train)))\n",
    "    #Root mean squared error for train 952.91\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, rf_predict_test)))\n",
    "    #Root mean squared error for test: 949.88\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gbm_model(X_train, Y_train, X_test, Y_test):\n",
    "    params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "              'learning_rate': 0.01, 'loss': 'ls'}\n",
    "    gbm = ensemble.GradientBoostingRegressor(**params)\n",
    "    gbm.fit(X_train, Y_train)\n",
    "    gbm_predict_train = gbm.predict(X_train)\n",
    "    gbm_predict_test = gbm.predict(X_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, gbm_predict_train)))\n",
    "    #Root mean squared error for train:  863.21\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, gbm_predict_test)))\n",
    "    #Root mean squared error for test: 867.61\n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction(model, data):\n",
    "    model_loaded = joblib.load(model)\n",
    "    pred = model_loaded.predict(data)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train = pd.read_csv(r'D:\\Learn\\DoorDash\\historical_data.csv')\n",
    "\n",
    "a0 = create_target(Train)\n",
    "a1 = create_time_feature(a0)\n",
    "a = process_continuous_features(a1)\n",
    "b = impute_market_id(a)\n",
    "c = bin_store_category(b)\n",
    "d = bin_order_protocol(c)\n",
    "e = make_store_id_cont(d)\n",
    "Train_processed = select_features(e, 'Train')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_processed.to_csv(r'D:\\Learn\\DoorDash\\Train_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_in_train = Train_processed['duration']\n",
    "del Train_processed['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197421,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_in_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3779.0\n",
       "1     4024.0\n",
       "2     1781.0\n",
       "3     3075.0\n",
       "4     2390.0\n",
       "5     2300.0\n",
       "6     1584.0\n",
       "7     1965.0\n",
       "8     1586.0\n",
       "9     3192.0\n",
       "10    2786.0\n",
       "11    8067.0\n",
       "12    2563.0\n",
       "13    2282.0\n",
       "14    2273.0\n",
       "15    2988.0\n",
       "16    5267.0\n",
       "17    4976.0\n",
       "18    4296.0\n",
       "19    3019.0\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_in_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197421, 19)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NumFeatures = select_features(e, 'Train')[1]\n",
    "CatFeatures = select_features(e, 'Train')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['total_items', 'subtotal', 'num_distinct_items', 'min_item_price', 'max_item_price', 'total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders', 'estimated_store_to_consumer_driving_duration'] +++ ['market_id', 'store_id_rebinned', 'store_primary_category_rebinned', 'order_protocol', 'created_at_month', 'created_at_dayOfWeek', 'created_at_hour', 'created_at_isWeekend', 'created_at_isHoliday', 'estimated_order_place_duration_rebinned']\n"
     ]
    }
   ],
   "source": [
    "print(NumFeatures, \"+++\",CatFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_ready_encoded = scale_oneHot_X(Train_processed, NumFeatures, CatFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train_ready = pd.concat([target_in_train, Train_ready_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  0,\n",
       "            ...\n",
       "            82, 83, 84, 85, 86, 87, 88, 89, 90, 91],\n",
       "           dtype='int64', length=101)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_ready_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test= train_test_split(Train_ready_encoded, target_in_train, test_size=0.4, random_state=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118452, 101)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118452,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78969, 101)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78969,)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197421"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "78969 + 118452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 1373.49\n",
      "Root mean squared error for test: 67061827560.87\n"
     ]
    }
   ],
   "source": [
    "linear_model = lin_model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 1437.61\n",
      "Root mean squared error for test: 30348.94\n"
     ]
    }
   ],
   "source": [
    "rf_model = rf_model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 1137.68\n",
      "Root mean squared error for test: 30345.70\n"
     ]
    }
   ],
   "source": [
    "gbm_model = gbm_model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbm_model_saved.pkl']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(linear_model, 'linear_model_saved.pkl')\n",
    "joblib.dump(rf_model, 'rf_model_saved.pkl')\n",
    "joblib.dump(gbm_model, 'gbm_model_saved.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_pred = make_prediction('linear_model_saved.pkl', combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_pred = make_prediction('rf_model_saved.pkl', combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm_pred = make_prediction('gbm_model_saved.pkl', combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78969 78969 78969\n"
     ]
    }
   ],
   "source": [
    "print(len(lm_pred),len(rf_pred),len(gbm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2202.03125,  2563.0625 ,  2526.53125,  3119.125  ,  1892.78125,\n",
       "        2942.25   ,  2732.09375,  2344.5    ,  3560.65625,  2685.53125,\n",
       "        3286.15625,  3185.5    ,  3128.59375,  2779.375  ,  3078.46875,\n",
       "        2990.09375,  2709.5    ,  3143.1875 ,  2089.90625,  3032.28125])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2434.83114527,  2879.63629676,  2966.90820199,  2631.93984603,\n",
       "        2434.83114527,  2879.63629676,  2755.90217238,  2434.83114527,\n",
       "        3057.91951435,  3174.66495311,  2960.06055137,  3057.91951435,\n",
       "        3456.09710311,  3007.64534283,  3162.62670436,  2924.23096759,\n",
       "        2796.09974542,  2879.63629676,  2755.90217238,  2960.06055137])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2199.4393632 ,  2606.55976438,  3029.99940799,  2958.2590211 ,\n",
       "        2046.84291021,  2828.20985816,  2674.09562267,  2166.88809262,\n",
       "        3395.55113147,  2736.05968081,  3012.30572648,  3020.09480717,\n",
       "        3121.16744013,  2823.23085902,  3233.56301021,  2740.95619139,\n",
       "        2714.77857972,  2857.8193394 ,  2357.68889923,  2744.87323666])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
