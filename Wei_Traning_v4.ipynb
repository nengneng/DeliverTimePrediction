{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import OneHotEncoder, scale, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math \n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import ensemble\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target Variable: duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_target(df):\n",
    "    # drop those records that have missing actual delivery time\n",
    "    df = df[pd.notnull(df['actual_delivery_time'])]\n",
    "    #df['created_at_datetime'] = df['created_at'].astype(\"datetime64[s]\")\n",
    "    #df['actual_delivery_time_datetime'] = df['actual_delivery_time'].astype(\"datetime64[s]\")\n",
    "    df['duration'] = df['actual_delivery_time'].astype(\"datetime64[s]\") - df['created_at'].astype(\"datetime64[s]\")\n",
    "    df['duration'] = df['duration'] / np.timedelta64(1, 's')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create features based on order creation time\n",
    "- create created_at_year, created_at_month, created_at_day, created_at_date, created_at_dayOfWeek, \n",
    "- created_at_time, created_at_hour, created_at_minute, created_at_second, created_at_isWeekend,\n",
    "- created_at_isHoliday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_time_feature(df):       \n",
    "    df['created_at_datetime'] = df['created_at'].astype(\"datetime64[s]\")\n",
    "    df['created_at_year'], df['created_at_month'], df['created_at_day'], df['created_at_date'], df['created_at_dayOfWeek'], df['created_at_time'], df['created_at_hour'], df['created_at_minute'], df['created_at_second'] = df['created_at_datetime'].dt.year, df['created_at_datetime'].dt.month, df['created_at_datetime'].dt.day, df['created_at_datetime'].dt.date, df['created_at_datetime'].dt.dayofweek, df['created_at_datetime'].dt.time, df['created_at_datetime'].dt.hour, df['created_at_datetime'].dt.minute, df['created_at_datetime'].dt.second\n",
    "    df.loc[df['created_at_dayOfWeek'].isin([5, 6]), 'created_at_isWeekend'] = 1\n",
    "    df.loc[df['created_at_dayOfWeek'].isin([0, 1, 2, 3, 4]), 'created_at_isWeekend'] = 0\n",
    "    cal = calendar()\n",
    "    holidays = cal.holidays(start=df['created_at_date'].min(), end=df['created_at_date'].max())\n",
    "    df['created_at_isHoliday'] = np.where(df.created_at_datetime.dt.normalize().isin(holidays), 1, 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cap some numerical featuress, fill missing values, re-bin categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_continuous_features(df):\n",
    "    \n",
    "    def bin_num(x, a=251, b=446):\n",
    "        if x == a:\n",
    "             return 'fast'\n",
    "        elif x == b:\n",
    "             return 'slow'\n",
    "        else:\n",
    "            return 'other'\n",
    "    \n",
    "    df['total_items'][(df['total_items'] > 20)] = 20\n",
    "    df['subtotal'][df['subtotal'] > 12000] = 12000\n",
    "    df['num_distinct_items'][df['num_distinct_items'] > 16] = 16\n",
    "    df['min_item_price'][(df['min_item_price'] < 0)] = 0\n",
    "    df['min_item_price'][(df['min_item_price'] > 5000)] = 5000\n",
    "\n",
    "    df['max_item_price'][(df['max_item_price'] < 0)] = 0\n",
    "    df['max_item_price'][(df['max_item_price'] > 5000)] = 5000\n",
    "\n",
    "    df['total_onshift_dashers'][df['total_onshift_dashers'] < 0] = 0\n",
    "    df['total_onshift_dashers'] = df['total_onshift_dashers'].fillna(int(df['total_onshift_dashers'].mean()))\n",
    "    \n",
    "    df['total_busy_dashers'][df['total_busy_dashers'] < 0] = 0\n",
    "    df['total_busy_dashers'] = df['total_busy_dashers'].fillna(int(df['total_busy_dashers'].mean()))\n",
    "    \n",
    "    df['total_outstanding_orders'][df['total_outstanding_orders'] < 0] = 0\n",
    "    df['total_outstanding_orders'] = df['total_outstanding_orders'].fillna(int(df['total_outstanding_orders'].mean()))\n",
    "    \n",
    "    df['estimated_order_place_duration_rebinned'] =  df['estimated_order_place_duration'].apply(bin_num)\n",
    "    df['estimated_store_to_consumer_driving_duration'] = df['estimated_store_to_consumer_driving_duration'].fillna(int(df['estimated_store_to_consumer_driving_duration'].mean()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Cardinality: store_id, calculate the number of orders for each store_id, then bucket it to cat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_store_id_cont(df):\n",
    "    store_counts_df = pd.DataFrame(df['store_id'].value_counts().reset_index().rename(columns={'index': 'store_id', 0: 'store_id_count'}))\n",
    "    store_counts_df.columns = ['store_id', 'store_id_count']\n",
    "    store_counts_df = store_counts_df.sort_values(by='store_id', ascending=True)\n",
    "    df = pd.merge(df, store_counts_df, on='store_id', how='left')\n",
    "    df['store_id_rebinned'] = df['store_id']\n",
    "    df['store_id_rebinned'][(df['store_id_count'] <500) & (df['store_id_count'] >= 400)] = '[400, 500)'\n",
    "    df['store_id_rebinned'][(df['store_id_count'] <400) & (df['store_id_count'] >= 200)] = '[200, 400)'\n",
    "    df['store_id_rebinned'][(df['store_id_count'] <200) & (df['store_id_count'] >= 50)] = '[50, 200)'\n",
    "    df['store_id_rebinned'][df['store_id_count'] <50] = '[0, 50)'\n",
    "    return df,store_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Cardinality: store_category, calculate the number of orders for each store_category, then bucket it to cat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_store_category_cont(df):\n",
    "    df['store_primary_category'][df['store_primary_category'].isnull()] = 'Unknown'\n",
    "    \n",
    "    store_primary_category_counts_df = pd.DataFrame(df['store_primary_category'].value_counts().reset_index().rename(columns={'index': 'store_primary_category', 0: 'store_primary_category_count'}))\n",
    "    store_primary_category_counts_df.columns = ['store_primary_category', 'store_primary_category_count']\n",
    "    df = pd.merge(df, store_primary_category_counts_df, on='store_primary_category', how='left')\n",
    "    \n",
    "    df['store_primary_category_rebinned'] = df['store_primary_category']\n",
    "    df['store_primary_category_rebinned'][df['store_primary_category_rebinned'].isnull()] = 'Unknown'\n",
    "    df['store_primary_category_rebinned'][(df['store_primary_category_count'] <3000) & (df['store_primary_category_count'] >= 2000)] = '[2000, 3000)'\n",
    "    df['store_primary_category_rebinned'][(df['store_primary_category_count'] <2000) & (df['store_primary_category_count'] >= 1000)] = '[1000, 2000)'\n",
    "    df['store_primary_category_rebinned'][(df['store_primary_category_count'] <1000) & (df['store_primary_category_count'] >= 200)] = '[200, 1000)'\n",
    "    df['store_primary_category_rebinned'][df['store_primary_category_count'] <200] = '[0, 200)'\n",
    "    return df, store_primary_category_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute market_id mising values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute_market_id(df):\n",
    "    df['market_id'][df['market_id'].isnull()] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute order_protocol mising values and re-bin small buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute_order_protocol(df):\n",
    "    df['order_protocol'][df['order_protocol'].isnull()] = 0\n",
    "    df['order_protocol'].loc[df['order_protocol'] == 6] = 0\n",
    "    df['order_protocol'].loc[df['order_protocol'] == 7] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training/Testing set, cat/numerica features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_features(df,TrainOrScore):\n",
    "    if TrainOrScore == 'Train':\n",
    "        TrainFeatures = df[['duration', 'market_id', 'store_id_rebinned', 'store_primary_category_rebinned',\n",
    "                            'order_protocol',  'total_items', 'subtotal', 'num_distinct_items', 'min_item_price',\n",
    "                            'max_item_price','total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders',\n",
    "                            'estimated_store_to_consumer_driving_duration', 'created_at_month', 'created_at_dayOfWeek',\n",
    "                            'created_at_hour', 'created_at_isWeekend', 'created_at_isHoliday',\n",
    "                            'estimated_order_place_duration_rebinned']]\n",
    "    else:\n",
    "        TrainFeatures = df[['market_id', 'store_id_rebinned', 'store_primary_category_rebinned',\n",
    "                    'order_protocol',  'total_items', 'subtotal', 'num_distinct_items', 'min_item_price',\n",
    "                    'max_item_price','total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders',\n",
    "                    'estimated_store_to_consumer_driving_duration', 'created_at_month', 'created_at_dayOfWeek',\n",
    "                    'created_at_hour', 'created_at_isWeekend', 'created_at_isHoliday',\n",
    "                    'estimated_order_place_duration_rebinned']]\n",
    "        \n",
    "    TrainFeatures[['market_id', 'store_id_rebinned', 'store_primary_category_rebinned', 'order_protocol', 'created_at_month',\n",
    "                   'created_at_dayOfWeek', 'created_at_hour',  'created_at_isWeekend', 'created_at_isHoliday', \n",
    "                   'estimated_order_place_duration_rebinned']] = TrainFeatures[['market_id', 'store_id_rebinned', \n",
    "                                                                               'store_primary_category_rebinned', \n",
    "                                                                                'order_protocol',\n",
    "                                                                                'created_at_month', 'created_at_dayOfWeek',\n",
    "                                                                                'created_at_hour',  'created_at_isWeekend',\n",
    "                                                                                'created_at_isHoliday', 'estimated_order_place_duration_rebinned']].astype(object)\n",
    "    NumFeatures = ['total_items', 'subtotal', 'num_distinct_items', 'min_item_price',  'max_item_price',\n",
    "                   'total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders',\n",
    "                   'estimated_store_to_consumer_driving_duration']\n",
    "    CatFeatures = ['market_id', 'store_id_rebinned', 'store_primary_category_rebinned',  'order_protocol',\n",
    "                   'created_at_month', 'created_at_dayOfWeek', 'created_at_hour', 'created_at_isWeekend',\n",
    "                   'created_at_isHoliday', 'estimated_order_place_duration_rebinned']\n",
    "    return TrainFeatures, NumFeatures, CatFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHot encoding for Categorical feature, scale numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_oneHot_X(input_x, features_num, features_cat):\n",
    "    # scale numerical features\n",
    "    input_x_scale = scale(input_x[features_num])\n",
    "    \n",
    "    # OneHot cat features\n",
    "    le=LabelEncoder()\n",
    "    enc = OneHotEncoder()\n",
    "    Cat_Train = input_x[features_cat].apply(le.fit_transform)\n",
    "    enc.fit(Cat_Train)\n",
    "    input_x_oneHot = enc.transform(Cat_Train).toarray()\n",
    "    \n",
    "    output_x = pd.concat([pd.DataFrame(input_x_scale), pd.DataFrame(input_x_oneHot)], axis=1)\n",
    "    output_x.columns = [i for i in range(output_x.shape[1])]\n",
    "    return output_x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Regular Linear Model\n",
    "def lin_model(X_train, Y_train, X_test, Y_test):\n",
    "    lm = linear_model.LinearRegression()\n",
    "    lm.fit(X_train, Y_train)\n",
    "    lm_predict_train = lm.predict(X_train)\n",
    "    lm_predict_test = lm.predict(X_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, lm_predict_train)))\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, lm_predict_test)))\n",
    "    return lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lasso\n",
    "def lin_model_lasso(X_train, Y_train, X_test, Y_test, alpha):\n",
    "    lm_lasso = linear_model.Lasso(alpha = alpha)\n",
    "    lm_lasso.fit(X_train, Y_train)\n",
    "    lm_lasso_predict_train = lm_lasso.predict(X_train)\n",
    "    lm_lasso_predict_test = lm_lasso.predict(X_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, lm_lasso_predict_train)))\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, lm_lasso_predict_test)))\n",
    "    return lm_lasso, math.sqrt(mean_squared_error(Y_train, lm_lasso_predict_train)), math.sqrt(mean_squared_error(Y_test, lm_lasso_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ridge\n",
    "def lin_model_ridge(X_train, Y_train, X_test, Y_test, alpha):\n",
    "    lm_ridge = Ridge(alpha = alpha)\n",
    "    lm_ridge.fit(X_train, Y_train)\n",
    "    lm_ridge_predict_train = lm_ridge.predict(X_train)\n",
    "    lm_ridge_predict_test = lm_ridge.predict(X_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, lm_ridge_predict_train)))\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, lm_ridge_predict_test)))\n",
    "    return lm_ridge, math.sqrt(mean_squared_error(Y_train, lm_ridge_predict_train)), math.sqrt(mean_squared_error(Y_test, lm_ridge_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_model(X_train, Y_train, X_test, Y_test):\n",
    "    rf = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    rf_predict_train = rf.predict(X_train)\n",
    "    rf_predict_test = rf.predict(X_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, rf_predict_train)))\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, rf_predict_test)))\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_model_grid_search(X_train, Y_train):  \n",
    "    param_grid = {\"n_estimators\": [500, 1000],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"max_features\": [10, 20],\n",
    "    \"min_samples_split\": [20, 50],\n",
    "    \"min_samples_leaf\": [10, 20],\n",
    "    \"bootstrap\": [True, False]}\n",
    "    \n",
    "    rf = RandomForestRegressor(random_state=0)\n",
    "    grid = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1)\n",
    "    grid.fit(X_train, Y_train)\n",
    "    print(grid.best_score_)\n",
    "    print(grid.best_params_)\n",
    "    return grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Random Forest using the best parameter from grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_with_best_parameters(X_train, Y_train, X_test, Y_test, best_param):\n",
    "    rf = RandomForestRegressor(bootstrap=best_param['bootstrap'],max_depth=best_param['max_depth'],\n",
    "                               max_features=best_param['max_features'],min_samples_leaf=best_param['min_samples_leaf'],\n",
    "                               min_samples_split=best_param['min_samples_split'],n_estimators=best_param['n_estimators'],\n",
    "                               random_state=0)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    rf_predict_train = rf.predict(X_train)\n",
    "    rf_predict_test = rf.predict(X_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, rf_predict_train)))\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, rf_predict_test)))\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gbm_model(X_train, Y_train, X_test, Y_test):\n",
    "    params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "              'learning_rate': 0.01, 'loss': 'ls'}\n",
    "    gbm = ensemble.GradientBoostingRegressor(**params)\n",
    "    gbm.fit(X_train, Y_train)\n",
    "    gbm_predict_train = gbm.predict(X_train)\n",
    "    gbm_predict_test = gbm.predict(X_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, gbm_predict_train)))\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, gbm_predict_test)))\n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gbm_model_grid_search(X_train, Y_train):\n",
    "    param_grid = {'max_depth': [3, 5], 'learning_rate': [0.01, 0.1],\n",
    "              'min_samples_split': [10, 20]}\n",
    "    gbm = ensemble.GradientBoostingRegressor(n_estimators=500)\n",
    "    grid = GridSearchCV(estimator=gbm, param_grid=param_grid, n_jobs=-1)\n",
    "    grid.fit(X_train, Y_train)\n",
    "    print(grid.best_score_)\n",
    "    print(grid.best_params_)\n",
    "    return grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit GBM using the best parameter from grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gbm_with_best_parameters(X_train, Y_train, X_test, Y_test, best_param):\n",
    "    gbm = ensemble.GradientBoostingRegressor(learning_rate=best_param['learning_rate'],max_depth=best_param['max_depth'],\n",
    "                                             min_samples_split=best_param['min_samples_split'])\n",
    "    gbm.fit(X_train, Y_train)\n",
    "    gbm_predict_train = gbm.predict(X_train)\n",
    "    gbm_predict_test = gbm.predict(X_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, gbm_predict_train)))\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, gbm_predict_test)))\n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit GBM on whole training set using the best parameter from grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gbm_with_best_parameters_whole_train_set(X_train, Y_train, best_param):\n",
    "    gbm = ensemble.GradientBoostingRegressor(learning_rate=best_param['learning_rate'],max_depth=best_param['max_depth'],\n",
    "                                             min_samples_split=best_param['min_samples_split'])\n",
    "    gbm.fit(X_train, Y_train)\n",
    "    gbm_predict_train = gbm.predict(X_train)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, gbm_predict_train)))\n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions using saved pickle model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction(model, data):\n",
    "    model_loaded = joblib.load(model)\n",
    "    pred = model_loaded.predict(data)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train = pd.read_csv(r'D:\\Learn\\DoorDash\\historical_data.csv')\n",
    "\n",
    "a0 = create_target(Train)\n",
    "a1 = create_time_feature(a0)\n",
    "a = process_continuous_features(a1)\n",
    "b = impute_market_id(a)\n",
    "c = impute_order_protocol(b)\n",
    "\n",
    "d = make_store_category_cont(c)[0]\n",
    "e = make_store_id_cont(d)[0]\n",
    "\n",
    "store_category_count_table = make_store_category_cont(c)[1]\n",
    "make_store_id_cont_table = make_store_id_cont(d)[1]\n",
    "\n",
    "# Save the look up table of store_category and store_id for later scoring use \n",
    "store_category_count_table.to_csv(r'D:\\Learn\\DoorDash\\store_category_count_table.csv', index=False)\n",
    "make_store_id_cont_table.to_csv(r'D:\\Learn\\DoorDash\\make_store_id_cont_table.csv', index=False)\n",
    "\n",
    "Train_processed = select_features(e, 'Train')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cap target variable to 2 hours, create target variable and training set for sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_processed['duration'][Train_processed['duration'] > 3600] = 3600\n",
    "target_in_train = Train_processed['duration']\n",
    "del Train_processed['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197421,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_in_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197421, 19)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create numeric features and cat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumFeatures = select_features(e, 'Train')[1]\n",
    "CatFeatures = select_features(e, 'Train')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumFeatures are: ['total_items', 'subtotal', 'num_distinct_items', 'min_item_price', 'max_item_price', 'total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders', 'estimated_store_to_consumer_driving_duration']\n",
      "CatFeatures are: ['market_id', 'store_id_rebinned', 'store_primary_category_rebinned', 'order_protocol', 'created_at_month', 'created_at_dayOfWeek', 'created_at_hour', 'created_at_isWeekend', 'created_at_isHoliday', 'estimated_order_place_duration_rebinned']\n"
     ]
    }
   ],
   "source": [
    "print(\"NumFeatures are: {}\".format(NumFeatures))\n",
    "print(\"CatFeatures are: {}\".format(CatFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHot encode cat features and scale numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_ready_encoded = scale_oneHot_X(Train_processed, NumFeatures, CatFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
       "            ...\n",
       "             91,  92,  93,  94,  95,  96,  97,  98,  99, 100],\n",
       "           dtype='int64', length=101)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_ready_encoded.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training and testing data from the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test= train_test_split(Train_ready_encoded, target_in_train, test_size=0.4, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15870</th>\n",
       "      <td>0.347130</td>\n",
       "      <td>2.559182</td>\n",
       "      <td>0.815810</td>\n",
       "      <td>0.124688</td>\n",
       "      <td>4.589361</td>\n",
       "      <td>0.370669</td>\n",
       "      <td>0.432625</td>\n",
       "      <td>0.237004</td>\n",
       "      <td>1.390680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>-0.500001</td>\n",
       "      <td>-0.487392</td>\n",
       "      <td>-0.411608</td>\n",
       "      <td>-0.795906</td>\n",
       "      <td>0.668467</td>\n",
       "      <td>-0.234041</td>\n",
       "      <td>-0.054497</td>\n",
       "      <td>-0.417191</td>\n",
       "      <td>-0.421600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154028</th>\n",
       "      <td>-0.076435</td>\n",
       "      <td>-0.328271</td>\n",
       "      <td>-0.411608</td>\n",
       "      <td>-1.059487</td>\n",
       "      <td>-0.609927</td>\n",
       "      <td>-0.929456</td>\n",
       "      <td>-0.898842</td>\n",
       "      <td>-0.734376</td>\n",
       "      <td>1.550453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174814</th>\n",
       "      <td>3.312087</td>\n",
       "      <td>2.146135</td>\n",
       "      <td>3.884355</td>\n",
       "      <td>-0.941263</td>\n",
       "      <td>-0.845181</td>\n",
       "      <td>-1.262046</td>\n",
       "      <td>-1.256065</td>\n",
       "      <td>-1.051561</td>\n",
       "      <td>-0.932873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163203</th>\n",
       "      <td>0.770695</td>\n",
       "      <td>0.884814</td>\n",
       "      <td>1.429519</td>\n",
       "      <td>-0.214478</td>\n",
       "      <td>0.714059</td>\n",
       "      <td>0.793965</td>\n",
       "      <td>0.919748</td>\n",
       "      <td>0.752430</td>\n",
       "      <td>-1.412192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "15870   0.347130  2.559182  0.815810  0.124688  4.589361  0.370669  0.432625   \n",
       "581    -0.500001 -0.487392 -0.411608 -0.795906  0.668467 -0.234041 -0.054497   \n",
       "154028 -0.076435 -0.328271 -0.411608 -1.059487 -0.609927 -0.929456 -0.898842   \n",
       "174814  3.312087  2.146135  3.884355 -0.941263 -0.845181 -1.262046 -1.256065   \n",
       "163203  0.770695  0.884814  1.429519 -0.214478  0.714059  0.793965  0.919748   \n",
       "\n",
       "             7         8    9   ...   91   92   93   94   95   96   97   98   \\\n",
       "15870   0.237004  1.390680  0.0 ...   0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
       "581    -0.417191 -0.421600  0.0 ...   0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0   \n",
       "154028 -0.734376  1.550453  0.0 ...   0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0   \n",
       "174814 -1.051561 -0.932873  0.0 ...   0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "163203  0.752430 -1.412192  0.0 ...   0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "\n",
       "        99   100  \n",
       "15870   0.0  1.0  \n",
       "581     0.0  0.0  \n",
       "154028  0.0  0.0  \n",
       "174814  0.0  1.0  \n",
       "163203  0.0  1.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit different models defined above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "linear_model = lin_model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression: find the best alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.96\n",
      "Root mean squared error for train: 591.51\n",
      "Root mean squared error for test: 590.10\n",
      "Root mean squared error for train: 591.66\n",
      "Root mean squared error for test: 590.26\n",
      "Root mean squared error for train: 591.89\n",
      "Root mean squared error for test: 590.49\n",
      "Root mean squared error for train: 592.14\n",
      "Root mean squared error for test: 590.76\n",
      "Root mean squared error for train: 592.40\n",
      "Root mean squared error for test: 591.05\n",
      "Root mean squared error for train: 592.68\n",
      "Root mean squared error for test: 591.35\n",
      "Root mean squared error for train: 592.93\n",
      "Root mean squared error for test: 591.61\n",
      "Root mean squared error for train: 593.21\n",
      "Root mean squared error for test: 591.91\n",
      "Root mean squared error for train: 593.46\n",
      "Root mean squared error for test: 592.17\n",
      "Root mean squared error for train: 593.70\n",
      "Root mean squared error for test: 592.42\n",
      "Root mean squared error for train: 593.93\n",
      "Root mean squared error for test: 592.66\n",
      "Root mean squared error for train: 594.11\n",
      "Root mean squared error for test: 592.82\n",
      "Root mean squared error for train: 594.26\n",
      "Root mean squared error for test: 592.95\n",
      "Root mean squared error for train: 594.41\n",
      "Root mean squared error for test: 593.10\n",
      "Root mean squared error for train: 594.56\n",
      "Root mean squared error for test: 593.23\n",
      "Root mean squared error for train: 594.72\n",
      "Root mean squared error for test: 593.37\n",
      "Root mean squared error for train: 594.86\n",
      "Root mean squared error for test: 593.50\n",
      "Root mean squared error for train: 595.00\n",
      "Root mean squared error for test: 593.63\n",
      "Root mean squared error for train: 595.16\n",
      "Root mean squared error for test: 593.77\n",
      "Root mean squared error for train: 595.32\n",
      "Root mean squared error for test: 593.91\n",
      "Root mean squared error for train: 595.47\n",
      "Root mean squared error for test: 594.06\n",
      "Root mean squared error for train: 595.63\n",
      "Root mean squared error for test: 594.20\n",
      "Root mean squared error for train: 595.79\n",
      "Root mean squared error for test: 594.36\n",
      "Root mean squared error for train: 595.95\n",
      "Root mean squared error for test: 594.51\n",
      "Root mean squared error for train: 596.11\n",
      "Root mean squared error for test: 594.67\n",
      "Root mean squared error for train: 596.27\n",
      "Root mean squared error for test: 594.82\n",
      "Root mean squared error for train: 596.42\n",
      "Root mean squared error for test: 594.96\n",
      "Root mean squared error for train: 596.57\n",
      "Root mean squared error for test: 595.10\n",
      "Root mean squared error for train: 596.72\n",
      "Root mean squared error for test: 595.25\n",
      "Root mean squared error for train: 596.88\n",
      "Root mean squared error for test: 595.40\n",
      "Root mean squared error for train: 597.02\n",
      "Root mean squared error for test: 595.53\n",
      "Root mean squared error for train: 597.16\n",
      "Root mean squared error for test: 595.66\n",
      "Root mean squared error for train: 597.29\n",
      "Root mean squared error for test: 595.79\n",
      "Root mean squared error for train: 597.42\n",
      "Root mean squared error for test: 595.92\n",
      "Root mean squared error for train: 597.56\n",
      "Root mean squared error for test: 596.05\n",
      "Root mean squared error for train: 597.70\n",
      "Root mean squared error for test: 596.19\n",
      "Root mean squared error for train: 597.84\n",
      "Root mean squared error for test: 596.33\n",
      "Root mean squared error for train: 597.98\n",
      "Root mean squared error for test: 596.47\n",
      "Root mean squared error for train: 598.12\n",
      "Root mean squared error for test: 596.60\n",
      "Root mean squared error for train: 598.23\n",
      "Root mean squared error for test: 596.71\n",
      "Root mean squared error for train: 598.35\n",
      "Root mean squared error for test: 596.82\n",
      "Root mean squared error for train: 598.48\n",
      "Root mean squared error for test: 596.94\n",
      "Root mean squared error for train: 598.60\n",
      "Root mean squared error for test: 597.06\n",
      "Root mean squared error for train: 598.73\n",
      "Root mean squared error for test: 597.18\n",
      "Root mean squared error for train: 598.86\n",
      "Root mean squared error for test: 597.30\n",
      "Root mean squared error for train: 599.00\n",
      "Root mean squared error for test: 597.43\n",
      "Root mean squared error for train: 599.14\n",
      "Root mean squared error for test: 597.56\n",
      "Root mean squared error for train: 599.28\n",
      "Root mean squared error for test: 597.69\n",
      "Root mean squared error for train: 599.42\n",
      "Root mean squared error for test: 597.83\n",
      "Root mean squared error for train: 599.57\n",
      "Root mean squared error for test: 597.97\n",
      "Root mean squared error for train: 599.72\n",
      "Root mean squared error for test: 598.11\n",
      "Root mean squared error for train: 599.87\n",
      "Root mean squared error for test: 598.26\n",
      "Root mean squared error for train: 600.03\n",
      "Root mean squared error for test: 598.41\n",
      "Root mean squared error for train: 600.19\n",
      "Root mean squared error for test: 598.56\n",
      "Root mean squared error for train: 600.35\n",
      "Root mean squared error for test: 598.71\n",
      "Root mean squared error for train: 600.51\n",
      "Root mean squared error for test: 598.86\n",
      "Root mean squared error for train: 600.67\n",
      "Root mean squared error for test: 599.02\n",
      "Root mean squared error for train: 600.84\n",
      "Root mean squared error for test: 599.18\n",
      "Root mean squared error for train: 601.00\n",
      "Root mean squared error for test: 599.33\n",
      "Root mean squared error for train: 601.15\n",
      "Root mean squared error for test: 599.48\n",
      "Root mean squared error for train: 601.31\n",
      "Root mean squared error for test: 599.64\n",
      "Root mean squared error for train: 601.47\n",
      "Root mean squared error for test: 599.80\n",
      "Root mean squared error for train: 601.64\n",
      "Root mean squared error for test: 599.96\n",
      "Root mean squared error for train: 601.81\n",
      "Root mean squared error for test: 600.12\n",
      "Root mean squared error for train: 601.98\n",
      "Root mean squared error for test: 600.28\n",
      "Root mean squared error for train: 602.15\n",
      "Root mean squared error for test: 600.45\n",
      "Root mean squared error for train: 602.32\n",
      "Root mean squared error for test: 600.62\n",
      "Root mean squared error for train: 602.50\n",
      "Root mean squared error for test: 600.79\n",
      "Root mean squared error for train: 602.68\n",
      "Root mean squared error for test: 600.97\n",
      "Root mean squared error for train: 602.86\n",
      "Root mean squared error for test: 601.15\n",
      "Root mean squared error for train: 603.05\n",
      "Root mean squared error for test: 601.33\n",
      "Root mean squared error for train: 603.24\n",
      "Root mean squared error for test: 601.51\n",
      "Root mean squared error for train: 603.42\n",
      "Root mean squared error for test: 601.69\n",
      "Root mean squared error for train: 603.61\n",
      "Root mean squared error for test: 601.88\n",
      "Root mean squared error for train: 603.80\n",
      "Root mean squared error for test: 602.06\n",
      "Root mean squared error for train: 603.99\n",
      "Root mean squared error for test: 602.25\n",
      "Root mean squared error for train: 604.18\n",
      "Root mean squared error for test: 602.43\n",
      "Root mean squared error for train: 604.35\n",
      "Root mean squared error for test: 602.60\n",
      "Root mean squared error for train: 604.52\n",
      "Root mean squared error for test: 602.77\n",
      "Root mean squared error for train: 604.69\n",
      "Root mean squared error for test: 602.94\n",
      "Root mean squared error for train: 604.87\n",
      "Root mean squared error for test: 603.12\n",
      "Root mean squared error for train: 605.05\n",
      "Root mean squared error for test: 603.29\n",
      "Root mean squared error for train: 605.23\n",
      "Root mean squared error for test: 603.47\n",
      "Root mean squared error for train: 605.41\n",
      "Root mean squared error for test: 603.65\n",
      "Root mean squared error for train: 605.60\n",
      "Root mean squared error for test: 603.84\n",
      "Root mean squared error for train: 605.79\n",
      "Root mean squared error for test: 604.02\n",
      "Root mean squared error for train: 605.98\n",
      "Root mean squared error for test: 604.21\n",
      "Root mean squared error for train: 606.17\n",
      "Root mean squared error for test: 604.40\n",
      "Root mean squared error for train: 606.36\n",
      "Root mean squared error for test: 604.59\n",
      "Root mean squared error for train: 606.56\n",
      "Root mean squared error for test: 604.78\n",
      "Root mean squared error for train: 606.76\n",
      "Root mean squared error for test: 604.98\n",
      "Root mean squared error for train: 606.96\n",
      "Root mean squared error for test: 605.17\n",
      "Root mean squared error for train: 607.16\n",
      "Root mean squared error for test: 605.37\n",
      "Root mean squared error for train: 607.36\n",
      "Root mean squared error for test: 605.58\n",
      "Root mean squared error for train: 607.57\n",
      "Root mean squared error for test: 605.78\n",
      "Root mean squared error for train: 607.78\n",
      "Root mean squared error for test: 605.99\n",
      "Root mean squared error for train: 607.99\n",
      "Root mean squared error for test: 606.20\n",
      "Root mean squared error for train: 608.20\n",
      "Root mean squared error for test: 606.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 608.42\n",
      "Root mean squared error for test: 606.62\n",
      "[591.4155672950541, 591.5092907574001, 591.6649817691649, 591.8905540232211, 592.1356368222652, 592.4031614498787, 592.6773534601319, 592.9307740779834, 593.2097587658197, 593.4581592705081, 593.7013770276182, 593.9344279436302, 594.1110878259205, 594.2592326255259, 594.4137844342156, 594.5620298952425, 594.7167504082004, 594.8588028456877, 595.004497134325, 595.15877756599, 595.3174962461333, 595.4703384956507, 595.6263361134986, 595.7875930306931, 595.9467609366886, 596.1121803642799, 596.2651486569608, 596.4158347715157, 596.5685664244918, 596.7246130895783, 596.8839440566211, 597.0218853833587, 597.156552448559, 597.2855061698906, 597.4184009296905, 597.5551752850872, 597.6958777422267, 597.8404875658445, 597.9793775104121, 598.1163952664027, 598.23354541853, 598.3536379381642, 598.476673697472, 598.6026552990406, 598.7315726720681, 598.8634283531148, 598.9982216403137, 599.1359278620442, 599.2760743639211, 599.4191383920707, 599.5651172493676, 599.7176129930958, 599.8740352388751, 600.0334530632629, 600.1934231123864, 600.3503277830516, 600.510068405471, 600.6726445681546, 600.8355304537664, 600.9958305387614, 601.1532463988473, 601.3126473883374, 601.474640539576, 601.6392224264184, 601.8063922102202, 601.9761464809256, 602.1484836822736, 602.3234021603678, 602.5008985141558, 602.6809715914417, 602.8636179763852, 603.0488358915491, 603.2366234755142, 603.4229349832082, 603.6110364314266, 603.8016375554654, 603.9947355484219, 604.17738530424, 604.347702793684, 604.5201690692737, 604.6947823022767, 604.8715415171819, 605.0504430718279, 605.2314859345606, 605.4146681909809, 605.5999888698201, 605.7874440818284, 605.9770328014688, 606.1687540561023, 606.3626037961498, 606.5585809975457, 606.7566835886231, 606.9569105821969, 607.1592576873654, 607.3637238740125, 607.5703070074507, 607.779006102294, 607.9898166422216, 608.2027375901594, 608.4177679567657] [589.9600964192067, 590.0986357382616, 590.2558603561893, 590.4878665380592, 590.758284047545, 591.0543605265955, 591.3464073472416, 591.6141031337266, 591.9077256616534, 592.168672587159, 592.422680591451, 592.6559503192323, 592.8193108601612, 592.9535936289459, 593.095208530766, 593.2274535962191, 593.3666122788707, 593.4954064866821, 593.6277129686356, 593.7686069022108, 593.9139274412466, 594.0555549606507, 594.2024502503338, 594.3551988305815, 594.5099063072769, 594.671209231779, 594.8157870159984, 594.9562592507468, 595.0990255225299, 595.2452750502894, 595.3952716321986, 595.5287115276059, 595.6599834701963, 595.7868834532435, 595.9177641293055, 596.052537425453, 596.1912759938019, 596.3339469964513, 596.4694902138457, 596.6023533320064, 596.7118661811134, 596.8243186492872, 596.9397124885642, 597.058045339501, 597.1793185969558, 597.3035295042677, 597.4306724678095, 597.5607290084507, 597.6931221230116, 597.8284342254993, 597.966667753276, 598.1105600020542, 598.258160141917, 598.4087588202646, 598.560478538306, 598.7105061991339, 598.8633745692562, 599.0190730773294, 599.1757524538764, 599.3312546657911, 599.483830653024, 599.6383931487702, 599.7955498223084, 599.9553072941494, 600.1176547970006, 600.2825989156685, 600.4501331698219, 600.620251054585, 600.7929590331693, 600.9682462314588, 601.1461190218868, 601.3265707638342, 601.5095949108247, 601.6921202281447, 601.876610971999, 602.063613499333, 602.2531160413689, 602.4327033619979, 602.6005457055405, 602.7705353310726, 602.9426704865828, 603.1169546298585, 603.2933752371537, 603.4719357521834, 603.6526343168217, 603.835474351933, 604.0204432072509, 604.2075442887458, 604.3967809633622, 604.5881406057173, 604.7816265714526, 604.9772367652428, 605.1749744266872, 605.3748267772494, 605.5767970866336, 605.7808832587134, 605.9870884948573, 606.1953999173215, 606.4058207043745, 606.6183540043854]\n"
     ]
    }
   ],
   "source": [
    "alpha_lst = np.arange(0, 10, 0.1)\n",
    "RMSE_train = [0]*len(alpha_lst)\n",
    "RMSE_test = [0]*len(alpha_lst)\n",
    "from sklearn import linear_model\n",
    "\n",
    "for i in range(len(alpha_lst)):\n",
    "    model_run = lin_model_lasso(X_train, Y_train, X_test, Y_test, alpha_lst[i])\n",
    "    RMSE_train[i] = model_run[1]\n",
    "    RMSE_test[i] = model_run[2]\n",
    "print(RMSE_train,RMSE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njDEGgP8D4Oki8SASFk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c1daa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(alpha_lst, RMSE_train)\n",
    "plt.plot(alpha_lst, RMSE_test)\n",
    "plt.legend(['RMSE_train', 'RMSE_test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression: find the best alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 3646728836586476355273733911347200.00\n",
      "Root mean squared error for test: 3669287604680430600796716832653312.00\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.96\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.96\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.96\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.96\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.96\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.96\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.96\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.96\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.42\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.97\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.98\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.99\n",
      "Root mean squared error for train: 591.43\n",
      "Root mean squared error for test: 589.99\n",
      "[3.6467288365864764e+33, 591.4156453661747, 591.4158388623366, 591.4161040704823, 591.4164129606665, 591.416747223524, 591.4170947451921, 591.4174474518526, 591.4177999538373, 591.4181486719374, 591.4184912627586, 591.4188262340772, 591.4191526834818, 591.4194701185065, 591.4197783315072, 591.4200773118417, 591.4203671837944, 591.4206481624615, 591.4209205222905, 591.4211845746116, 591.4214406516002, 591.4216890948716, 591.4219302474248, 591.422164448019, 591.4223920273173, 591.4226133053218, 591.4228285897448, 591.4230381750614, 591.4232423420542, 591.4234413577096, 591.4236354753646, 591.4238249350261, 591.4240099638076, 591.4241907764408, 591.4243675758333, 591.4245405536485, 591.4247098908922, 591.4248757584944, 591.4250383178779, 591.4251977215094, 591.4253541134271, 591.4255076297444, 591.4256583991295, 591.4258065432564, 591.4259521772328, 591.4260954100012, 591.4262363447158, 591.4263750790965, 591.4265117057597, 591.4266463125288, 591.4267789827242, 591.4269097954343, 591.4270388257688, 591.4271661450957, 591.4272918212635, 591.4274159188063, 591.4275384991387, 591.4276596207359, 591.4277793393023, 591.4278977079307, 591.4280147772486, 591.4281305955575, 591.4282452089623, 591.4283586614924, 591.4284709952152, 591.4285822503427, 591.4286924653317, 591.4288016769767, 591.4289099204984, 591.4290172296265, 591.4291236366762, 591.4292291726217, 591.429333867165, 591.4294377488001, 591.4295408448729, 591.4296431816397, 591.4297447843197, 591.4298456771464, 591.4299458834157, 591.4300454255296, 591.4301443250404, 591.43024260269, 591.4303402784477, 591.4304373715469, 591.4305339005177, 591.4306298832205, 591.4307253368752, 591.4308202780904, 591.4309147228903, 591.431008686741, 591.4311021845748, 591.4311952308125, 591.4312878393869, 591.431380023762, 591.4314717969548, 591.431563171552, 591.4316541597292, 591.4317447732677, 591.4318350235703, 591.4319249216771] [3.6692876046804306e+33, 589.9608124796407, 589.9614923399935, 589.9621295306454, 589.9627235646794, 589.963276700731, 589.9637923322888, 589.964274183598, 589.9647259158659, 589.9651509454281, 589.9655523718583, 589.9659329624759, 589.9662951647804, 589.9666411316024, 589.9669727508962, 589.9672916759782, 589.9675993541393, 589.9678970527137, 589.9681858823151, 589.9684668172649, 589.9687407134102, 589.9690083235781, 589.9692703109475, 589.9695272605973, 589.9697796894768, 589.9700280550159, 589.970272762564, 589.9705141718267, 589.9707526024391, 589.9709883388028, 589.9712216342862, 589.9714527148811, 589.9716817823906, 589.9719090172126, 589.9721345807744, 589.972358617667, 589.9725812575185, 589.9728026166401, 589.9730227994775, 589.9732418998894, 589.9734600022792, 589.9736771825939, 589.9738935092108, 589.9741090437246, 589.9743238416456, 589.9745379530221, 589.9747514229941, 589.9749642922883, 589.9751765976588, 589.9753883722825, 589.9755996461128, 589.9758104461949, 589.9760207969524, 589.9762307204404, 589.9764402365755, 589.9766493633427, 589.9768581169807, 589.9770665121496, 589.9772745620817, 589.9774822787182, 589.9776896728322, 589.9778967541403, 589.9781035314027, 589.9783100125148, 589.9785162045902, 589.9787221140341, 589.9789277466126, 589.9791331075135, 589.9793382014018, 589.9795430324707, 589.9797476044882, 589.9799519208376, 589.9801559845562, 589.9803597983698, 589.9805633647242, 589.9807666858127, 589.9809697636033, 589.9811725998616, 589.9813751961722, 589.9815775539583, 589.9817796744996, 589.981981558948, 589.9821832083423, 589.9823846236219, 589.9825858056383, 589.9827867551668, 589.9829874729155, 589.9831879595351, 589.9833882156267, 589.9835882417497, 589.9837880384274, 589.9839876061544, 589.9841869454013, 589.9843860566199, 589.9845849402475, 589.984783596711, 589.9849820264305, 589.9851802298227, 589.9853782073033, 589.9855759592903]\n"
     ]
    }
   ],
   "source": [
    "alpha_lst = np.arange(0, 10, 0.1)\n",
    "RMSE_train = [0]*len(alpha_lst)\n",
    "RMSE_test = [0]*len(alpha_lst)\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "for i in range(len(alpha_lst)):\n",
    "    model_run = lin_model_ridge(X_train, Y_train, X_test, Y_test, alpha_lst[i])\n",
    "    RMSE_train[i] = model_run[1]\n",
    "    RMSE_test[i] = model_run[2]\n",
    "print(RMSE_train,RMSE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4IBgZmaJA4KZmQEOCGZmljggmJkZAP8fuV6yC/8jzKQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22eb63128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(alpha_lst[1:], RMSE_train[1:])\n",
    "plt.plot(alpha_lst[1:], RMSE_test[1:])\n",
    "plt.legend(['RMSE_train', 'RMSE_test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 665.47\n",
      "Root mean squared error for test: 664.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = rf_model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search best hyper parameters for RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.186093201827\n",
      "{'bootstrap': True, 'max_depth': 5, 'max_features': 20, 'min_samples_leaf': 10, 'min_samples_split': 50, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "best_parameters_rf = rf_model_grid_search(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 5,\n",
       " 'max_features': 20,\n",
       " 'min_samples_leaf': 10,\n",
       " 'min_samples_split': 50,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the RF model using best parameters found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 644.90\n",
      "Root mean squared error for test: 644.03\n"
     ]
    }
   ],
   "source": [
    "rf_model_best = rf_with_best_parameters(X_train, Y_train, X_test, Y_test,best_parameters_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 600.67\n",
      "Root mean squared error for test: 602.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "gbm_model = gbm_model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search best hyper parameters for GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.381693403666\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "best_parameters_gbm = gbm_model_grid_search(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the GBM model using best parameters found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 563.85\n",
      "Root mean squared error for test: 571.78\n"
     ]
    }
   ],
   "source": [
    "gbm_model_best = gbm_with_best_parameters(X_train, Y_train, X_test, Y_test,best_parameters_gbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since GBM model achieves the best performance, refit GBM using all training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 566.91\n"
     ]
    }
   ],
   "source": [
    "gbm_model_use = gbm_with_best_parameters_whole_train_set(Train_ready_encoded, target_in_train, best_parameters_gbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Trained GBM model to local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbm_model_saved.pkl']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gbm_model_use, 'gbm_model_saved.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing: load the saved GBM model and make some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm_pred = make_prediction('gbm_model_saved.pkl', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78969\n"
     ]
    }
   ],
   "source": [
    "print(len(gbm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2293.50835784,  2838.62334103,  2251.74874425,  2240.7351142 ,\n",
       "        2416.20007106,  2501.93681813,  2561.08997439,  2275.75416258,\n",
       "        2998.79859211,  2248.73661143,  3098.01418079,  2359.43527697,\n",
       "        2831.39361821,  2402.98098392,  3033.23640343,  3122.78087725,\n",
       "        2559.8937146 ,  2720.02531779,  2467.67426725,  2498.88182806])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
