{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import OneHotEncoder, scale, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import ensemble\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_time_feature(df):\n",
    "    \n",
    "    #create created_at_year, created_at_month, created_at_day, created_at_date, created_at_dayOfWeek, \n",
    "    #created_at_time, created_at_hour, created_at_minute, created_at_second, created_at_isWeekend,\n",
    "    #created_at_isHoliday\n",
    "    \n",
    "    df['created_at_datetime'] = df['created_at'].astype(\"datetime64[s]\")\n",
    "    #df['actual_delivery_time_datetime'] = df['actual_delivery_time'].astype(\"datetime64[s]\")\n",
    "\n",
    "    df['created_at_year'], df['created_at_month'], df['created_at_day'], df['created_at_date'], df['created_at_dayOfWeek'], df['created_at_time'], df['created_at_hour'], df['created_at_minute'], df['created_at_second'] = df['created_at_datetime'].dt.year, df['created_at_datetime'].dt.month, df['created_at_datetime'].dt.day, df['created_at_datetime'].dt.date, df['created_at_datetime'].dt.dayofweek, df['created_at_datetime'].dt.time, df['created_at_datetime'].dt.hour, df['created_at_datetime'].dt.minute, df['created_at_datetime'].dt.second\n",
    "\n",
    "    df.loc[df['created_at_dayOfWeek'].isin([5, 6]), 'created_at_isWeekend'] = 1\n",
    "    df.loc[df['created_at_dayOfWeek'].isin([0, 1, 2, 3, 4]), 'created_at_isWeekend'] = 0\n",
    "\n",
    "    cal = calendar()\n",
    "    holidays = cal.holidays(start=df['created_at_date'].min(), end=df['created_at_date'].max())\n",
    "    df['created_at_isHoliday'] = np.where(df.created_at_datetime.dt.normalize().isin(holidays), 1, 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_continuous_features(df):\n",
    "    \n",
    "    def bin_num(x, a=251, b=446):\n",
    "        if x == a:\n",
    "             return 'fast'\n",
    "        elif x == b:\n",
    "             return 'slow'\n",
    "        else:\n",
    "            return 'other'\n",
    "    \n",
    "    #df = df.loc[df['total_items'] < 20]\n",
    "    #df = df.loc[df['subtotal'] < 12000]\n",
    "    #df = df.loc[df['num_distinct_items'] < 16]\n",
    "    #df = df.loc[(df['min_item_price'] > 0) & (df['min_item_price'] <= 5000)]\n",
    "    #df = df.loc[(df['max_item_price'] > 0) & (df['max_item_price'] <= 5000)]\n",
    "    \n",
    "    #df = df.loc[df['total_onshift_dashers'] > 0]\n",
    "    df['total_onshift_dashers'] = df['total_onshift_dashers'].fillna(int(df['total_onshift_dashers'].mean()))\n",
    "    \n",
    "    #df = df.loc[df['total_busy_dashers'] > 0]\n",
    "    df['total_busy_dashers'] = df['total_busy_dashers'].fillna(int(df['total_busy_dashers'].mean()))\n",
    "    \n",
    "    #df = df.loc[df['total_outstanding_orders'] > 0]\n",
    "    df['total_outstanding_orders'] = df['total_outstanding_orders'].fillna(int(df['total_outstanding_orders'].mean()))\n",
    "    \n",
    "    df['estimated_order_place_duration_rebinned'] =  df['estimated_order_place_duration'].apply(bin_num)\n",
    "    df['estimated_store_to_consumer_driving_duration'] = df['estimated_store_to_consumer_driving_duration'].fillna(int(df['estimated_store_to_consumer_driving_duration'].mean()))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate number of orders for each store\n",
    "def make_store_id_cont(df):\n",
    "    store_counts_df = pd.DataFrame(df['store_id'].value_counts().reset_index().rename(columns={'index': 'store_id', 0: 'store_id_count'}))\n",
    "    store_counts_df.columns = ['store_id', 'store_id_count']\n",
    "    store_counts_df = store_counts_df.sort_values(by='store_id', ascending=True)\n",
    "    df = pd.merge(df, store_counts_df, on='store_id', how='left')\n",
    "    df['store_id_rebinned'] = df['store_id']\n",
    "    df['store_id_rebinned'][(df['store_id_count'] <500) & (df['store_id_count'] >= 400)] = '[400, 500)'\n",
    "    df['store_id_rebinned'][(df['store_id_count'] <400) & (df['store_id_count'] >= 200)] = '[200, 400)'\n",
    "    df['store_id_rebinned'][(df['store_id_count'] <200) & (df['store_id_count'] >= 50)] = '[50, 200)'\n",
    "    df['store_id_rebinned'][df['store_id_count'] <50] = '[0, 50)'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_store_category(df):\n",
    "    df['store_primary_category'][df['store_primary_category'].isnull()] = 'Unknown'\n",
    "    \n",
    "    store_primary_category_counts_df = pd.DataFrame(df['store_primary_category'].value_counts().reset_index().rename(columns={'index': 'store_primary_category', 0: 'store_primary_category_count'}))\n",
    "    store_primary_category_counts_df.columns = ['store_primary_category', 'store_primary_category_count']\n",
    "    df = pd.merge(df, store_primary_category_counts_df, on='store_primary_category', how='left')\n",
    "    \n",
    "    #lst_store_primary_category=df['store_primary_category'].tolist()\n",
    "    #lst_store_primary_category_cnt = df['store_primary_category_count'].tolist()\n",
    "    #lst_store_primary_category_bin = [lst_store_primary_category[i] if lst_store_primary_category_cnt[i] > 300 else \"other2\" for i in range(len(lst_store_primary_category)) ]   \n",
    "    #df['store_primary_category_rebinned'] = lst_store_primary_category_bin\n",
    "    \n",
    "    df['store_primary_category_rebinned'] = df['store_primary_category']\n",
    "    df['store_primary_category_rebinned'][df['store_primary_category_rebinned'].isnull()] = 'Unknown'\n",
    "    df['store_primary_category_rebinned'][(df['store_primary_category_count'] <3000) & (df['store_primary_category_count'] >= 2000)] = '[2000, 3000)'\n",
    "    df['store_primary_category_rebinned'][(df['store_primary_category_count'] <2000) & (df['store_primary_category_count'] >= 1000)] = '[1000, 2000)'\n",
    "    df['store_primary_category_rebinned'][(df['store_primary_category_count'] <1000) & (df['store_primary_category_count'] >= 200)] = '[200, 1000)'\n",
    "    df['store_primary_category_rebinned'][df['store_primary_category_count'] <200] = '[0, 200)'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute_market_id(df):\n",
    "    df['market_id'][df['market_id'].isnull()] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_order_protocol(df):\n",
    "    df['order_protocol'][df['order_protocol'].isnull()] = 0\n",
    "    df['order_protocol'].loc[df['order_protocol'] == 6] = 0\n",
    "    df['order_protocol'].loc[df['order_protocol'] == 7] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_features(df,TrainOrScore):\n",
    "    if TrainOrScore == 'Train':\n",
    "        TrainFeatures = df[['duration', 'market_id', 'store_id_rebinned', 'store_primary_category_rebinned',\n",
    "                            'order_protocol',  'total_items', 'subtotal', 'num_distinct_items', 'min_item_price',\n",
    "                            'max_item_price','total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders',\n",
    "                            'estimated_store_to_consumer_driving_duration', 'created_at_month', 'created_at_dayOfWeek',\n",
    "                            'created_at_hour', 'created_at_isWeekend', 'created_at_isHoliday',\n",
    "                            'estimated_order_place_duration_rebinned']]\n",
    "    else:\n",
    "        TrainFeatures = df[['market_id', 'store_id_rebinned', 'store_primary_category_rebinned',\n",
    "                    'order_protocol',  'total_items', 'subtotal', 'num_distinct_items', 'min_item_price',\n",
    "                    'max_item_price','total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders',\n",
    "                    'estimated_store_to_consumer_driving_duration', 'created_at_month', 'created_at_dayOfWeek',\n",
    "                    'created_at_hour', 'created_at_isWeekend', 'created_at_isHoliday',\n",
    "                    'estimated_order_place_duration_rebinned']]\n",
    "        \n",
    "    TrainFeatures[['market_id', 'store_id_rebinned', 'store_primary_category_rebinned', 'order_protocol', 'created_at_month', 'created_at_dayOfWeek', 'created_at_hour',  'created_at_isWeekend', 'created_at_isHoliday', 'estimated_order_place_duration_rebinned']] = TrainFeatures[['market_id', 'store_id_rebinned', 'store_primary_category_rebinned', 'order_protocol', 'created_at_month', 'created_at_dayOfWeek', 'created_at_hour',  'created_at_isWeekend', 'created_at_isHoliday', 'estimated_order_place_duration_rebinned']].astype(object)\n",
    "    NumFeatures = ['total_items', 'subtotal', 'num_distinct_items', 'min_item_price',  'max_item_price','total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders', 'estimated_store_to_consumer_driving_duration']\n",
    "    CatFeatures = ['market_id', 'store_id_rebinned', 'store_primary_category_rebinned',  'order_protocol', 'created_at_month', 'created_at_dayOfWeek', 'created_at_hour', 'created_at_isWeekend', 'created_at_isHoliday', 'estimated_order_place_duration_rebinned']\n",
    "    return TrainFeatures, NumFeatures, CatFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_oneHot_X(input_x, features_num, features_cat):\n",
    "    # scale numerical features\n",
    "    input_x_scale = scale(input_x[features_num])\n",
    "    \n",
    "    # OneHot cat features\n",
    "    le=LabelEncoder()\n",
    "    enc = OneHotEncoder()\n",
    "    \n",
    "    Cat_Train = input_x[features_cat].apply(le.fit_transform)\n",
    "    enc.fit(Cat_Train)\n",
    "    input_x_oneHot = enc.transform(Cat_Train).toarray()\n",
    "    \n",
    "    output_x = pd.concat([pd.DataFrame(input_x_scale), pd.DataFrame(input_x_oneHot)], axis=1)\n",
    "\n",
    "    return output_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction(model, data):\n",
    "    model_loaded = joblib.load(model)\n",
    "    pred = model_loaded.predict(data)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_unlabeled_data(input_file):\n",
    "    loaded_data = []\n",
    "    with open(input_file) as f:\n",
    "        for line in f:\n",
    "            loaded_data.append(json.loads(line))\n",
    "            \n",
    "    created_at_lst = [x['created_at'] for x in loaded_data]\n",
    "    delivery_id_lst = [x['delivery_id'] for x in loaded_data]\n",
    "    estimated_order_place_duration_lst = [x['estimated_order_place_duration'] for x in loaded_data]\n",
    "    estimated_store_to_consumer_driving_duration_lst = [x['estimated_store_to_consumer_driving_duration'] for x in loaded_data]\n",
    "    market_id_lst = [x['market_id'] for x in loaded_data]\n",
    "    max_item_price_lst = [x['max_item_price'] for x in loaded_data]\n",
    "    min_item_price_lst = [x['min_item_price'] for x in loaded_data]\n",
    "    num_distinct_items_lst = [x['num_distinct_items'] for x in loaded_data]\n",
    "    order_protocol_lst = [x['order_protocol'] for x in loaded_data]\n",
    "    platform_lst = [x['platform'] for x in loaded_data]\n",
    "    store_id_lst = [x['store_id'] for x in loaded_data]\n",
    "    store_primary_category_lst = [x['store_primary_category'] for x in loaded_data]\n",
    "    subtotal_lst = [x['subtotal'] for x in loaded_data]\n",
    "    total_busy_dashers_lst = [x['total_busy_dashers'] for x in loaded_data]\n",
    "    total_items_lst = [x['total_items'] for x in loaded_data]\n",
    "    total_onshift_dashers_lst = [x['total_onshift_dashers'] for x in loaded_data]\n",
    "    total_outstanding_orders_lst = [x['total_outstanding_orders'] for x in loaded_data]\n",
    "    \n",
    "    unlabled_df = pd.DataFrame(\n",
    "        {'created_at': created_at_lst,\n",
    "         'delivery_id': delivery_id_lst,\n",
    "         'estimated_order_place_duration': estimated_order_place_duration_lst,\n",
    "         'estimated_store_to_consumer_driving_duration': estimated_store_to_consumer_driving_duration_lst,\n",
    "         'market_id': market_id_lst,\n",
    "         'max_item_price': max_item_price_lst,\n",
    "         'min_item_price': min_item_price_lst,\n",
    "         'num_distinct_items': num_distinct_items_lst,\n",
    "         'order_protocol': order_protocol_lst,\n",
    "         'platform': platform_lst,\n",
    "         'store_id': store_id_lst,\n",
    "         'store_primary_category': store_primary_category_lst,\n",
    "         'subtotal': subtotal_lst,\n",
    "         'total_busy_dashers': total_busy_dashers_lst,\n",
    "         'total_items': total_items_lst,\n",
    "         'total_onshift_dashers': total_onshift_dashers_lst,\n",
    "         'total_outstanding_orders': total_outstanding_orders_lst\n",
    "        })\n",
    "    return unlabled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_target(df):\n",
    "    # drop those records that have missing actual delivery time\n",
    "    df = df[pd.notnull(df['actual_delivery_time'])]\n",
    "    #df['created_at_datetime'] = df['created_at'].astype(\"datetime64[s]\")\n",
    "    #df['actual_delivery_time_datetime'] = df['actual_delivery_time'].astype(\"datetime64[s]\")\n",
    "    df['duration'] = df['actual_delivery_time'].astype(\"datetime64[s]\") - df['created_at'].astype(\"datetime64[s]\")\n",
    "    df['duration'] = df['duration'] / np.timedelta64(1, 's')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled_json = r'D:/Learn/DoorDash/data_to_predict.json'\n",
    "unlabeled_df = load_unlabeled_data(unlabeled_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54778, 17)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled_df[['market_id','estimated_order_place_duration','estimated_store_to_consumer_driving_duration',\n",
    "             'max_item_price','min_item_price', 'num_distinct_items', 'order_protocol',\n",
    "             'subtotal','total_onshift_dashers','total_busy_dashers','total_items','total_onshift_dashers',\n",
    "             'total_outstanding_orders']] = unlabeled_df[['market_id','estimated_order_place_duration','estimated_store_to_consumer_driving_duration',\n",
    "             'max_item_price','min_item_price', 'num_distinct_items', 'order_protocol',\n",
    "             'subtotal','total_onshift_dashers','total_busy_dashers','total_items','total_onshift_dashers',\n",
    "             'total_outstanding_orders']].apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1 = create_time_feature(unlabeled_df)\n",
    "a = process_continuous_features(a1)\n",
    "b = impute_market_id(a)\n",
    "c = bin_store_category(b)\n",
    "d = bin_order_protocol(c)\n",
    "e = make_store_id_cont(d)\n",
    "unlabeled_ready = select_features(e, 'Test')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54778, 19)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_ready.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train = pd.read_csv(r'D:\\Learn\\DoorDash\\historical_data.csv')\n",
    "\n",
    "a0 = create_target(Train)\n",
    "a1 = create_time_feature(a0)\n",
    "a = process_continuous_features(a1)\n",
    "b = impute_market_id(a)\n",
    "c = bin_store_category(b)\n",
    "d = bin_order_protocol(c)\n",
    "e = make_store_id_cont(d)\n",
    "Train_ready = select_features(e, 'Train')[0]\n",
    "del Train_ready['duration'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_plus_unlabel = pd.concat([Train_ready, unlabeled_ready], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NumFeatures = select_features(e, 'Test')[1]\n",
    "CatFeatures = select_features(e, 'Test')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_plus_unlabel_encoded = scale_oneHot_X(train_plus_unlabel, NumFeatures,CatFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled_ready2 = train_plus_unlabel_encoded.tail(unlabeled_ready.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_pred = make_prediction('linear_model_saved.pkl', unlabeled_ready2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_pred = make_prediction('rf_model_saved.pkl', unlabeled_ready2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm_pred = make_prediction('gbm_model_saved.pkl', unlabeled_ready2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54778 54778 54778\n"
     ]
    }
   ],
   "source": [
    "print(len(lm_pred),len(rf_pred),len(gbm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3820.3125 ,  3248.09375,  3368.25   ,  3070.96875,  2790.34375,\n",
       "        4142.     ,  3298.09375,  2678.125  ,  2294.34375,  2667.71875,\n",
       "        1797.40625,  2229.09375,  2923.25   ,  2820.78125,  2658.90625,\n",
       "        2527.625  ,  2370.90625,  2262.71875,  2708.59375,  2937.03125])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3566.84448195,  2625.11019812,  3202.67299455,  2879.63629676,\n",
       "        2744.99607565,  3057.91951435,  2879.63629676,  2528.64391073,\n",
       "        2434.83114527,  2960.06055137,  2434.83114527,  2625.11019812,\n",
       "        3057.91951435,  3057.91951435,  3041.92910632,  2672.85212705,\n",
       "        2434.83114527,  2625.11019812,  2960.06055137,  3122.01565049])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3554.78663092,  3164.58918312,  3418.20169046,  3185.3913607 ,\n",
       "        2972.63129221,  3718.89304481,  3539.30491931,  2764.68586825,\n",
       "        2333.9713622 ,  2935.8126484 ,  2057.11700156,  2433.50642321,\n",
       "        2839.21028669,  2852.16433479,  2758.2507588 ,  2804.78376313,\n",
       "        2356.6763389 ,  2436.38133445,  2773.508449  ,  2918.31572916])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id = unlabeled_df['delivery_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54778"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({'delivery_id': unlabeled_df['delivery_id'], 'predicted_delivery_seconds': gbm_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df.to_csv(r'D:\\Learn\\DoorDash\\predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
