{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import OneHotEncoder, scale, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math \n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import ensemble\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_target(df):\n",
    "    # drop those records that have missing actual delivery time\n",
    "    df = df[pd.notnull(df['actual_delivery_time'])]\n",
    "    #df['created_at_datetime'] = df['created_at'].astype(\"datetime64[s]\")\n",
    "    #df['actual_delivery_time_datetime'] = df['actual_delivery_time'].astype(\"datetime64[s]\")\n",
    "    df['duration'] = df['actual_delivery_time'].astype(\"datetime64[s]\") - df['created_at'].astype(\"datetime64[s]\")\n",
    "    df['duration'] = df['duration'] / np.timedelta64(1, 's')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_time_feature(df):\n",
    "    \n",
    "    #create created_at_year, created_at_month, created_at_day, created_at_date, created_at_dayOfWeek, \n",
    "    #created_at_time, created_at_hour, created_at_minute, created_at_second, created_at_isWeekend,\n",
    "    #created_at_isHoliday\n",
    "    \n",
    "    df['created_at_datetime'] = df['created_at'].astype(\"datetime64[s]\")\n",
    "    #df['actual_delivery_time_datetime'] = df['actual_delivery_time'].astype(\"datetime64[s]\")\n",
    "\n",
    "    df['created_at_year'], df['created_at_month'], df['created_at_day'], df['created_at_date'], df['created_at_dayOfWeek'], df['created_at_time'], df['created_at_hour'], df['created_at_minute'], df['created_at_second'] = df['created_at_datetime'].dt.year, df['created_at_datetime'].dt.month, df['created_at_datetime'].dt.day, df['created_at_datetime'].dt.date, df['created_at_datetime'].dt.dayofweek, df['created_at_datetime'].dt.time, df['created_at_datetime'].dt.hour, df['created_at_datetime'].dt.minute, df['created_at_datetime'].dt.second\n",
    "\n",
    "    df.loc[df['created_at_dayOfWeek'].isin([5, 6]), 'created_at_isWeekend'] = 1\n",
    "    df.loc[df['created_at_dayOfWeek'].isin([0, 1, 2, 3, 4]), 'created_at_isWeekend'] = 0\n",
    "\n",
    "    cal = calendar()\n",
    "    holidays = cal.holidays(start=df['created_at_date'].min(), end=df['created_at_date'].max())\n",
    "    df['created_at_isHoliday'] = np.where(df.created_at_datetime.dt.normalize().isin(holidays), 1, 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_continuous_features(df):\n",
    "    \n",
    "    def bin_num(x, a=251, b=446):\n",
    "        if x == a:\n",
    "             return 'fast'\n",
    "        elif x == b:\n",
    "             return 'slow'\n",
    "        else:\n",
    "            return 'other'\n",
    "    \n",
    "    #df = df.loc[(df['total_items'] < 20)]\n",
    "    #df = df.loc[df['subtotal'] < 12000]\n",
    "    #df = df.loc[df['num_distinct_items'] < 16]\n",
    "    #df = df.loc[(df['min_item_price'] > 0) & (df['min_item_price'] <= 5000)]\n",
    "    #df = df.loc[(df['max_item_price'] > 0) & (df['max_item_price'] <= 5000)]\n",
    "    \n",
    "    df['total_items'][(df['total_items'] > 20)] = 20\n",
    "    df['subtotal'][df['subtotal'] > 12000] = 12000\n",
    "    df['num_distinct_items'][df['num_distinct_items'] > 16] = 16\n",
    "    df['min_item_price'][(df['min_item_price'] < 0)] = 0\n",
    "    df['min_item_price'][(df['min_item_price'] > 5000)] = 5000\n",
    "\n",
    "    df['max_item_price'][(df['max_item_price'] < 0)] = 0\n",
    "    df['max_item_price'][(df['max_item_price'] > 5000)] = 5000\n",
    "\n",
    "    \n",
    "    #df = df.loc[df['total_onshift_dashers'] > 0]\n",
    "    df['total_onshift_dashers'][df['total_onshift_dashers'] < 0] = 0\n",
    "    df['total_onshift_dashers'] = df['total_onshift_dashers'].fillna(int(df['total_onshift_dashers'].mean()))\n",
    "    \n",
    "    #df = df.loc[df['total_busy_dashers'] > 0]\n",
    "    df['total_busy_dashers'][df['total_busy_dashers'] < 0] = 0\n",
    "    df['total_busy_dashers'] = df['total_busy_dashers'].fillna(int(df['total_busy_dashers'].mean()))\n",
    "    \n",
    "    #df = df.loc[df['total_outstanding_orders'] > 0]\n",
    "    df['total_outstanding_orders'][df['total_outstanding_orders'] < 0] = 0\n",
    "    df['total_outstanding_orders'] = df['total_outstanding_orders'].fillna(int(df['total_outstanding_orders'].mean()))\n",
    "    \n",
    "    df['estimated_order_place_duration_rebinned'] =  df['estimated_order_place_duration'].apply(bin_num)\n",
    "    df['estimated_store_to_consumer_driving_duration'] = df['estimated_store_to_consumer_driving_duration'].fillna(int(df['estimated_store_to_consumer_driving_duration'].mean()))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate number of orders for each store\n",
    "def make_store_id_cont(df):\n",
    "    store_counts_df = pd.DataFrame(df['store_id'].value_counts().reset_index().rename(columns={'index': 'store_id', 0: 'store_id_count'}))\n",
    "    store_counts_df.columns = ['store_id', 'store_id_count']\n",
    "    store_counts_df = store_counts_df.sort_values(by='store_id', ascending=True)\n",
    "    df = pd.merge(df, store_counts_df, on='store_id', how='left')\n",
    "    df['store_id_rebinned'] = df['store_id']\n",
    "    df['store_id_rebinned'][(df['store_id_count'] <500) & (df['store_id_count'] >= 400)] = '[400, 500)'\n",
    "    df['store_id_rebinned'][(df['store_id_count'] <400) & (df['store_id_count'] >= 200)] = '[200, 400)'\n",
    "    df['store_id_rebinned'][(df['store_id_count'] <200) & (df['store_id_count'] >= 50)] = '[50, 200)'\n",
    "    df['store_id_rebinned'][df['store_id_count'] <50] = '[0, 50)'\n",
    "\n",
    "    return df,store_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_store_category_cont(df):\n",
    "    df['store_primary_category'][df['store_primary_category'].isnull()] = 'Unknown'\n",
    "    \n",
    "    store_primary_category_counts_df = pd.DataFrame(df['store_primary_category'].value_counts().reset_index().rename(columns={'index': 'store_primary_category', 0: 'store_primary_category_count'}))\n",
    "    store_primary_category_counts_df.columns = ['store_primary_category', 'store_primary_category_count']\n",
    "    df = pd.merge(df, store_primary_category_counts_df, on='store_primary_category', how='left')\n",
    "    \n",
    "    #lst_store_primary_category=df['store_primary_category'].tolist()\n",
    "    #lst_store_primary_category_cnt = df['store_primary_category_count'].tolist()\n",
    "    #lst_store_primary_category_bin = [lst_store_primary_category[i] if lst_store_primary_category_cnt[i] > 300 else \"other2\" for i in range(len(lst_store_primary_category)) ]   \n",
    "    #df['store_primary_category_rebinned'] = lst_store_primary_category_bin\n",
    "    \n",
    "    df['store_primary_category_rebinned'] = df['store_primary_category']\n",
    "    df['store_primary_category_rebinned'][df['store_primary_category_rebinned'].isnull()] = 'Unknown'\n",
    "    df['store_primary_category_rebinned'][(df['store_primary_category_count'] <3000) & (df['store_primary_category_count'] >= 2000)] = '[2000, 3000)'\n",
    "    df['store_primary_category_rebinned'][(df['store_primary_category_count'] <2000) & (df['store_primary_category_count'] >= 1000)] = '[1000, 2000)'\n",
    "    df['store_primary_category_rebinned'][(df['store_primary_category_count'] <1000) & (df['store_primary_category_count'] >= 200)] = '[200, 1000)'\n",
    "    df['store_primary_category_rebinned'][df['store_primary_category_count'] <200] = '[0, 200)'\n",
    "    return df, store_primary_category_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute_market_id(df):\n",
    "    df['market_id'][df['market_id'].isnull()] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute_order_protocol(df):\n",
    "    df['order_protocol'][df['order_protocol'].isnull()] = 0\n",
    "    df['order_protocol'].loc[df['order_protocol'] == 6] = 0\n",
    "    df['order_protocol'].loc[df['order_protocol'] == 7] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_features(df,TrainOrScore):\n",
    "    if TrainOrScore == 'Train':\n",
    "        TrainFeatures = df[['duration', 'market_id', 'store_id_rebinned', 'store_primary_category_rebinned',\n",
    "                            'order_protocol',  'total_items', 'subtotal', 'num_distinct_items', 'min_item_price',\n",
    "                            'max_item_price','total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders',\n",
    "                            'estimated_store_to_consumer_driving_duration', 'created_at_month', 'created_at_dayOfWeek',\n",
    "                            'created_at_hour', 'created_at_isWeekend', 'created_at_isHoliday',\n",
    "                            'estimated_order_place_duration_rebinned']]\n",
    "    else:\n",
    "        TrainFeatures = df[['market_id', 'store_id_rebinned', 'store_primary_category_rebinned',\n",
    "                    'order_protocol',  'total_items', 'subtotal', 'num_distinct_items', 'min_item_price',\n",
    "                    'max_item_price','total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders',\n",
    "                    'estimated_store_to_consumer_driving_duration', 'created_at_month', 'created_at_dayOfWeek',\n",
    "                    'created_at_hour', 'created_at_isWeekend', 'created_at_isHoliday',\n",
    "                    'estimated_order_place_duration_rebinned']]\n",
    "        \n",
    "    TrainFeatures[['market_id', 'store_id_rebinned', 'store_primary_category_rebinned', 'order_protocol', 'created_at_month',\n",
    "                   'created_at_dayOfWeek', 'created_at_hour',  'created_at_isWeekend', 'created_at_isHoliday', \n",
    "                   'estimated_order_place_duration_rebinned']] = TrainFeatures[['market_id', 'store_id_rebinned', \n",
    "                                                                               'store_primary_category_rebinned', \n",
    "                                                                                'order_protocol',\n",
    "                                                                                'created_at_month', 'created_at_dayOfWeek',\n",
    "                                                                                'created_at_hour',  'created_at_isWeekend',\n",
    "                                                                                'created_at_isHoliday', 'estimated_order_place_duration_rebinned']].astype(object)\n",
    "    NumFeatures = ['total_items', 'subtotal', 'num_distinct_items', 'min_item_price',  'max_item_price',\n",
    "                   'total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders',\n",
    "                   'estimated_store_to_consumer_driving_duration']\n",
    "    CatFeatures = ['market_id', 'store_id_rebinned', 'store_primary_category_rebinned',  'order_protocol',\n",
    "                   'created_at_month', 'created_at_dayOfWeek', 'created_at_hour', 'created_at_isWeekend',\n",
    "                   'created_at_isHoliday', 'estimated_order_place_duration_rebinned']\n",
    "    return TrainFeatures, NumFeatures, CatFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_oneHot_X(input_x, features_num, features_cat):\n",
    "    # scale numerical features\n",
    "    input_x_scale = scale(input_x[features_num])\n",
    "    \n",
    "    # OneHot cat features\n",
    "    le=LabelEncoder()\n",
    "    enc = OneHotEncoder()\n",
    "    \n",
    "    Cat_Train = input_x[features_cat].apply(le.fit_transform)\n",
    "    enc.fit(Cat_Train)\n",
    "    input_x_oneHot = enc.transform(Cat_Train).toarray()\n",
    "    \n",
    "    output_x = pd.concat([pd.DataFrame(input_x_scale), pd.DataFrame(input_x_oneHot)], axis=1)\n",
    "    output_x.columns = [i for i in range(output_x.shape[1])]\n",
    "\n",
    "    return output_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Regular Linear Model\n",
    "def lin_model(X_train, Y_train, X_test, Y_test):\n",
    "    lm = linear_model.LinearRegression()\n",
    "    lm.fit(X_train, Y_train)\n",
    "    lm_predict_train = lm.predict(X_train)\n",
    "    lm_predict_test = lm.predict(X_test)\n",
    "    #lm_predict_train = [Y_train.mean()]*len(Y_train)\n",
    "    #lm_predict_test = [Y_train.mean()]*len(Y_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, lm_predict_train)))\n",
    "    #Root mean squared error for train 896.74\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, lm_predict_test)))\n",
    "    #Root mean squared error for test: 893.58\n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lasso\n",
    "def lin_model_lasso(X_train, Y_train, X_test, Y_test, alpha):\n",
    "    lm_lasso = linear_model.Lasso(alpha = 0.1)\n",
    "    lm_lasso.fit(X_train, Y_train)\n",
    "    lm_lasso_predict_train = lm_lasso.predict(X_train)\n",
    "    lm_lasso_predict_test = lm_lasso.predict(X_test)\n",
    "    #lm_predict_train = [Y_train.mean()]*len(Y_train)\n",
    "    #lm_predict_test = [Y_train.mean()]*len(Y_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, lm_lasso_predict_train)))\n",
    "    #Root mean squared error for train 896.74\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, lm_lasso_predict_test)))\n",
    "    #Root mean squared error for test: 893.58\n",
    "    return lm_lasso, math.sqrt(mean_squared_error(Y_train, lm_lasso_predict_train)), math.sqrt(mean_squared_error(Y_test, lm_lasso_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ridge\n",
    "def lin_model_ridge(X_train, Y_train, X_test, Y_test, alpha):\n",
    "    lm_ridge = rideg(alpha = 0.1)\n",
    "    lm_ridge.fit(X_train, Y_train)\n",
    "    lm_ridge_predict_train = lm_ridge.predict(X_train)\n",
    "    lm_ridge_predict_test = lm_ridge.predict(X_test)\n",
    "    #lm_predict_train = [Y_train.mean()]*len(Y_train)\n",
    "    #lm_predict_test = [Y_train.mean()]*len(Y_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, lm_ridge_predict_train)))\n",
    "    #Root mean squared error for train 896.74\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, lm_ridge_predict_test)))\n",
    "    #Root mean squared error for test: 893.58\n",
    "    return lm_ridge, math.sqrt(mean_squared_error(Y_train, lm_ridge_predict_train)), math.sqrt(mean_squared_error(Y_test, lm_ridge_predict_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_model(X_train, Y_train, X_test, Y_test):\n",
    "    rf = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    rf_predict_train = rf.predict(X_train)\n",
    "    rf_predict_test = rf.predict(X_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, rf_predict_train)))\n",
    "    #Root mean squared error for train 952.91\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, rf_predict_test)))\n",
    "    #Root mean squared error for test: 949.88\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_model_grid_search(X_train, Y_train):\n",
    "    \n",
    "    param_grid = {\"n_estimators\": [500, 1000],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"max_features\": [10, 20],\n",
    "    \"min_samples_split\": [20, 50],\n",
    "    \"min_samples_leaf\": [10, 20],\n",
    "    \"bootstrap\": [True, False]}\n",
    "    \n",
    "    rf = RandomForestRegressor(random_state=0)\n",
    "    grid = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1)\n",
    "    grid.fit(X_train, Y_train)\n",
    "    print(grid.best_score_)\n",
    "    print(grid.best_params_)\n",
    "    return grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_with_best_parameters(X_train, Y_train, X_test, Y_test, best_par_set):\n",
    "    rf = RandomForestRegressor(best, random_state=0)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    rf_predict_train = rf.predict(X_train)\n",
    "    rf_predict_test = rf.predict(X_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, rf_predict_train)))\n",
    "    #Root mean squared error for train 952.91\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, rf_predict_test)))\n",
    "    #Root mean squared error for test: 949.88\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"n_estimators\": [200, 500],\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": [1, 3, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 3, 10],\n",
    "    \"bootstrap\": [True, False]}\n",
    "\n",
    "model = RandomForestRegressor(random_state=0)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gbm_model(X_train, Y_train, X_test, Y_test):\n",
    "    params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "              'learning_rate': 0.01, 'loss': 'ls'}\n",
    "    gbm = ensemble.GradientBoostingRegressor(**params)\n",
    "    gbm.fit(X_train, Y_train)\n",
    "    gbm_predict_train = gbm.predict(X_train)\n",
    "    gbm_predict_test = gbm.predict(X_test)\n",
    "    print(\"Root mean squared error for train: %.2f\" % math.sqrt(mean_squared_error(Y_train, gbm_predict_train)))\n",
    "    #Root mean squared error for train:  863.21\n",
    "    print(\"Root mean squared error for test: %.2f\" % math.sqrt(mean_squared_error(Y_test, gbm_predict_test)))\n",
    "    #Root mean squared error for test: 867.61\n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction(model, data):\n",
    "    model_loaded = joblib.load(model)\n",
    "    pred = model_loaded.predict(data)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train = pd.read_csv(r'D:\\Learn\\DoorDash\\historical_data.csv')\n",
    "\n",
    "a0 = create_target(Train)\n",
    "a1 = create_time_feature(a0)\n",
    "a = process_continuous_features(a1)\n",
    "b = impute_market_id(a)\n",
    "c = impute_order_protocol(b)\n",
    "\n",
    "d = make_store_category_cont(c)[0]\n",
    "e = make_store_id_cont(d)[0]\n",
    "\n",
    "store_category_count_table = make_store_category_cont(c)[1]\n",
    "make_store_id_cont_table = make_store_id_cont(d)[1]\n",
    "\n",
    "store_category_count_table.to_csv(r'D:\\Learn\\DoorDash\\store_category_count_table.csv', index=False)\n",
    "make_store_id_cont_table.to_csv(r'D:\\Learn\\DoorDash\\make_store_id_cont_table.csv', index=False)\n",
    "\n",
    "Train_processed = select_features(e, 'Train')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_processed['duration'][Train_processed['duration'] > 3600] = 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_in_train = Train_processed['duration']\n",
    "del Train_processed['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197421,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_in_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3600.0\n",
       "1     3600.0\n",
       "2     1781.0\n",
       "3     3075.0\n",
       "4     2390.0\n",
       "5     2300.0\n",
       "6     1584.0\n",
       "7     1965.0\n",
       "8     1586.0\n",
       "9     3192.0\n",
       "10    2786.0\n",
       "11    3600.0\n",
       "12    2563.0\n",
       "13    2282.0\n",
       "14    2273.0\n",
       "15    2988.0\n",
       "16    3600.0\n",
       "17    3600.0\n",
       "18    3600.0\n",
       "19    3019.0\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_in_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197421, 19)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NumFeatures = select_features(e, 'Train')[1]\n",
    "CatFeatures = select_features(e, 'Train')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['total_items', 'subtotal', 'num_distinct_items', 'min_item_price', 'max_item_price', 'total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders', 'estimated_store_to_consumer_driving_duration'] +++ ['market_id', 'store_id_rebinned', 'store_primary_category_rebinned', 'order_protocol', 'created_at_month', 'created_at_dayOfWeek', 'created_at_hour', 'created_at_isWeekend', 'created_at_isHoliday', 'estimated_order_place_duration_rebinned']\n"
     ]
    }
   ],
   "source": [
    "print(NumFeatures, \"+++\",CatFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_ready_encoded = scale_oneHot_X(Train_processed, NumFeatures, CatFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train_ready = pd.concat([target_in_train, Train_ready_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
       "            ...\n",
       "             91,  92,  93,  94,  95,  96,  97,  98,  99, 100],\n",
       "           dtype='int64', length=101)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_ready_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test= train_test_split(Train_ready_encoded, target_in_train, test_size=0.4, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15870</th>\n",
       "      <td>0.347130</td>\n",
       "      <td>2.559182</td>\n",
       "      <td>0.815810</td>\n",
       "      <td>0.124688</td>\n",
       "      <td>4.589361</td>\n",
       "      <td>0.370669</td>\n",
       "      <td>0.432625</td>\n",
       "      <td>0.237004</td>\n",
       "      <td>1.390680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>-0.500001</td>\n",
       "      <td>-0.487392</td>\n",
       "      <td>-0.411608</td>\n",
       "      <td>-0.795906</td>\n",
       "      <td>0.668467</td>\n",
       "      <td>-0.234041</td>\n",
       "      <td>-0.054497</td>\n",
       "      <td>-0.417191</td>\n",
       "      <td>-0.421600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154028</th>\n",
       "      <td>-0.076435</td>\n",
       "      <td>-0.328271</td>\n",
       "      <td>-0.411608</td>\n",
       "      <td>-1.059487</td>\n",
       "      <td>-0.609927</td>\n",
       "      <td>-0.929456</td>\n",
       "      <td>-0.898842</td>\n",
       "      <td>-0.734376</td>\n",
       "      <td>1.550453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174814</th>\n",
       "      <td>3.312087</td>\n",
       "      <td>2.146135</td>\n",
       "      <td>3.884355</td>\n",
       "      <td>-0.941263</td>\n",
       "      <td>-0.845181</td>\n",
       "      <td>-1.262046</td>\n",
       "      <td>-1.256065</td>\n",
       "      <td>-1.051561</td>\n",
       "      <td>-0.932873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163203</th>\n",
       "      <td>0.770695</td>\n",
       "      <td>0.884814</td>\n",
       "      <td>1.429519</td>\n",
       "      <td>-0.214478</td>\n",
       "      <td>0.714059</td>\n",
       "      <td>0.793965</td>\n",
       "      <td>0.919748</td>\n",
       "      <td>0.752430</td>\n",
       "      <td>-1.412192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "15870   0.347130  2.559182  0.815810  0.124688  4.589361  0.370669  0.432625   \n",
       "581    -0.500001 -0.487392 -0.411608 -0.795906  0.668467 -0.234041 -0.054497   \n",
       "154028 -0.076435 -0.328271 -0.411608 -1.059487 -0.609927 -0.929456 -0.898842   \n",
       "174814  3.312087  2.146135  3.884355 -0.941263 -0.845181 -1.262046 -1.256065   \n",
       "163203  0.770695  0.884814  1.429519 -0.214478  0.714059  0.793965  0.919748   \n",
       "\n",
       "             7         8    9   ...   91   92   93   94   95   96   97   98   \\\n",
       "15870   0.237004  1.390680  0.0 ...   0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
       "581    -0.417191 -0.421600  0.0 ...   0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0   \n",
       "154028 -0.734376  1.550453  0.0 ...   0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0   \n",
       "174814 -1.051561 -0.932873  0.0 ...   0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "163203  0.752430 -1.412192  0.0 ...   0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "\n",
       "        99   100  \n",
       "15870   0.0  1.0  \n",
       "581     0.0  0.0  \n",
       "154028  0.0  0.0  \n",
       "174814  0.0  1.0  \n",
       "163203  0.0  1.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118452, 101)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118452,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78969, 101)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78969,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197421"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "78969 + 118452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 591.51\n",
      "Root mean squared error for test: 590.10\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "linear_model = lin_model(X_train, Y_train, X_test, Y_test, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 665.47\n",
      "Root mean squared error for test: 664.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = rf_model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters_rf = rf_model_grid_search(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error for train: 600.67\n",
      "Root mean squared error for test: 602.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "gbm_model = gbm_model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbm_model_saved.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(linear_model, 'linear_model_saved.pkl')\n",
    "joblib.dump(rf_model, 'rf_model_saved.pkl')\n",
    "joblib.dump(gbm_model, 'gbm_model_saved.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_pred = make_prediction('linear_model_saved.pkl', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_pred = make_prediction('rf_model_saved.pkl', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm_pred = make_prediction('gbm_model_saved.pkl', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78969 78969 78969\n"
     ]
    }
   ],
   "source": [
    "print(len(lm_pred),len(rf_pred),len(gbm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2390.6640625,  2812.0859375,  2220.234375 ,  2308.9296875,\n",
       "        2233.7421875,  2438.3828125,  2568.6015625,  2278.1015625,\n",
       "        2989.9140625,  2408.015625 ,  3048.6171875,  2313.2578125,\n",
       "        2969.6953125,  2340.4609375,  3136.6796875,  2961.515625 ,\n",
       "        2439.8203125,  2775.2890625,  2542.3984375,  2284.4140625])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2650.3242264 ,  2954.29260843,  2268.87912797,  2575.72747166,\n",
       "        2268.87912797,  2590.89116275,  2686.63909013,  2650.3242264 ,\n",
       "        3202.19939432,  2386.86891341,  2650.3242264 ,  2679.92707392,\n",
       "        2700.33799324,  2650.3242264 ,  2568.62871291,  2686.63909013,\n",
       "        2575.72747166,  2650.3242264 ,  2994.35599239,  2679.92707392])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2567.69151735,  2840.9815715 ,  2370.89074489,  2328.98636186,\n",
       "        2325.39751797,  2592.829483  ,  2622.05198529,  2373.54291763,\n",
       "        2993.783579  ,  2333.9482885 ,  2768.28181379,  2442.92692151,\n",
       "        2777.95251252,  2448.66384235,  2939.86520252,  3014.16728322,\n",
       "        2428.23599071,  2641.08962181,  2713.25116329,  2636.0480359 ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
